{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR_PATH = '/work/nas/emotion/02_TFRecords/smile_all_v2_224_190422'\n",
    "TRAIN_OUTPUT_DIR_PATH = OUTPUT_DIR_PATH + \"/train\"\n",
    "VAL_OUTPUT_DIR_PATH = OUTPUT_DIR_PATH + \"/val\"\n",
    "\n",
    "LABEL_PATH = '/work/nas/emotion/02_TFRecords/smile_all_v2_224_190422/label.txt' # Could be file or dir that has folders named as labels\n",
    "\n",
    "DEBUG_IMAGES = False\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "INPUT_CHANNELS = 3\n",
    "NUM_CLASSES = 3\n",
    "BATCH_EPOCHS = 1000\n",
    "VAL_BATCH_SIZE = 64\n",
    "\n",
    "CKPT_DIR = '/work/nas/emotion/03_CheckPoint/smile_v2_224_mobilenet_190522/ckpt'\n",
    "LOAD_CKPT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV1 :\n",
    "    def __init__(self, learning_rate=0.01, lr_min=0.0001, lr_decay=0.94, lr_decay_epoch=5) :\n",
    "        self.learning_rate = learning_rate;\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_decay = lr_decay\n",
    "        self.lr_decay_epoch = lr_decay_epoch\n",
    "\n",
    "    def separable_conv2D(self, x, channels, strides=1) :\n",
    "        x = keras.layers.DepthwiseConv2D(3, strides, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = keras.layers.Conv2D(channels, 1, 1, padding='same')(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def create_model(self) :\n",
    "        inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='x')\n",
    "        x = keras.layers.Conv2D(32, 3, 2, padding='same')(inputs) # 112\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        x = self.separable_conv2D(x, 64)\n",
    "        x = self.separable_conv2D(x, 128, 2) # 56\n",
    "        x = self.separable_conv2D(x, 128)\n",
    "        x = self.separable_conv2D(x, 256, 2) # 28\n",
    "        x = self.separable_conv2D(x, 256)\n",
    "        x = self.separable_conv2D(x, 512, 2) # 14\n",
    "        for idx in range(5) :\n",
    "            x = self.separable_conv2D(x, 512)\n",
    "        x = self.separable_conv2D(x, 1024, 2) # 7\n",
    "        x = self.separable_conv2D(x, 1024)\n",
    "        x = keras.layers.AveragePooling2D(7)(x)\n",
    "        x = keras.layers.Flatten()(x)\n",
    "        x = keras.layers.Dense(1000, activation=tf.keras.activations.relu)(x)\n",
    "        x = keras.layers.Dropout(0.2)(x)\n",
    "        x = keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax, name='final')(x)\n",
    "           \n",
    "        model = keras.Model(inputs=[inputs], outputs=[x])\n",
    "#         model = keras.utils.multi_gpu_model(model, gpus=2)\n",
    "        model.compile(optimizer=tf.train.AdamOptimizer(self.learning_rate), \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_tfrecord(data_dir_path, batch_size) :\n",
    "    tfrecord_file_paths = tf.gfile.Glob('%s/*.tfrecord' % (data_dir_path))\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file_paths)\n",
    "    dataset = dataset.map(parse)\n",
    "    dataset = dataset.map(preprocess_dataset)\n",
    "#     dataset = dataset.repeat() # This dataset will go on forever   \n",
    "    dataset = dataset.shuffle(1000) # Set the number of datapoints you want to load and shuffle \n",
    "    dataset = dataset.batch(batch_size) # Set the batchsize\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def parse(data):\n",
    "    features = {\"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "                \"image/class/label\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/height\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/width\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/channels\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "    parsed_features = tf.parse_single_example(data, features)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(parsed_features['image/encoded'])\n",
    "    label = tf.cast(parsed_features[\"image/class/label\"], tf.int64)\n",
    "    width = tf.cast(parsed_features['image/width'], tf.int32)\n",
    "    height = tf.cast(parsed_features['image/height'], tf.int32)\n",
    "    channels = tf.cast(parsed_features[\"image/channels\"], tf.int64)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def preprocess_dataset(images, labels) :\n",
    "    images = tf.image.resize_images(images, (INPUT_SIZE, INPUT_SIZE))    \n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images = tf.subtract(images, 128.0)\n",
    "    images = tf.divide(images, 128.0)\n",
    "    images = dataset_flip_left_and_right(images)\n",
    "    images = dataset_rotate(images)\n",
    "    images = dataset_zoom(images)\n",
    "#     images = tf.divide(images, 255.0)\n",
    "#     labels = tf.one_hot(labels, NUM_CLASSES) # Create a one hot array for your labels\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def dataset_rotate(images) :\n",
    "    return tf.image.rot90(images, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "def dataset_flip_left_and_right(images) :\n",
    "    return tf.image.random_flip_left_right(images)\n",
    "\n",
    "def dataset_zoom(images) :\n",
    "    scales = list(np.arange(0.7, 1.0, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(images):\n",
    "        # Create different crops for an image\n",
    "        crops = tf.image.crop_and_resize([images], boxes=boxes, box_ind=np.zeros(len(scales)), crop_size=(INPUT_SIZE, INPUT_SIZE))\n",
    "        # Return a random crop\n",
    "        return crops[tf.random_uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "    choice = tf.random_uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: images, lambda: random_crop(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path) :    \n",
    "    labels = []\n",
    "    with open(label_path, 'r') as f :\n",
    "        for line in f.readlines() :\n",
    "            labels.append(line.strip())\n",
    "\n",
    "    return labels\n",
    "\n",
    "def make_directory(dir_path) :\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"Directory is created in \", dir_path)\n",
    "\n",
    "def show_images(image, label, width, height, channels) :\n",
    "    label_names = load_labels(LABEL_PATH)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    for idx in range(5) :\n",
    "        if channels == 1 :\n",
    "            image_data = tf.reshape(image[idx], [width[idx], height[idx]])\n",
    "            axes[idx].imshow(image_data, cmap='gray')  \n",
    "        else :\n",
    "            image_data = image[idx]\n",
    "            axes[idx].imshow(image_data)  \n",
    "\n",
    "        axes[idx].set_title(label_names[label[idx]])\n",
    "\n",
    "def get_dataset_steps(dataset) :\n",
    "    counter = 0\n",
    "    for _, _ in dataset :\n",
    "        counter += 1\n",
    "    return counter\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, epoch=10000) :\n",
    "    val_steps = get_dataset_steps(val_dataset)\n",
    "    # print(\"Val dataset steps : %d\" % val_steps)\n",
    "\n",
    "    make_directory(CKPT_DIR)\n",
    "        \n",
    "    total_epoch = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        for train_images, train_labels in train_dataset:\n",
    "            train_loss, train_accuracy = model.train_on_batch(train_images, train_labels)\n",
    "            total_epoch += 1\n",
    "\n",
    "            if total_epoch % 100 == 0 :\n",
    "                val_loss, val_accuracy = model.evaluate(val_dataset, steps=val_steps, verbose = 0)\n",
    "                print('Epoch #%d    Loss: %.6f    Train Accuracy: %.6f    Val accuracy: %.6f' % (total_epoch, train_loss, train_accuracy, val_accuracy))\n",
    "\n",
    "                if val_accuracy > best_accuracy :\n",
    "                    model.save('%s/mobilenet_emotion_%.2f_%d.h5' % (CKPT_DIR, val_accuracy, total_epoch))\n",
    "    #                 model.save_weights(CKPT_DIR + '/emotion_mobilenet_v1_{0:.2f}.h5'.format(val_accuracy))\n",
    "\n",
    "                    print(\"Save model of accuracy %.6f\" % val_accuracy)\n",
    "                    best_accuracy = val_accuracy\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 14, 14, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 7, 7, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 7, 7, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "final (Dense)                (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 4,267,811\n",
      "Trainable params: 4,245,923\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory is created in  /work/nas/emotion/03_CheckPoint/smile_v2_224_mobilenet_190522/ckpt\n",
      "Epoch #100    Loss: 0.637415    Train Accuracy: 0.687500    Val accuracy: 0.467333\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.467333\n",
      "Epoch #200    Loss: 0.458852    Train Accuracy: 0.781250    Val accuracy: 0.467333\n",
      "Epoch #300    Loss: 0.715083    Train Accuracy: 0.687500    Val accuracy: 0.467333\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.467333\n",
      "Epoch #400    Loss: 0.618129    Train Accuracy: 0.750000    Val accuracy: 0.467333\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.467333\n",
      "Epoch #500    Loss: 0.555719    Train Accuracy: 0.718750    Val accuracy: 0.467333\n",
      "Epoch #600    Loss: 0.564753    Train Accuracy: 0.718750    Val accuracy: 0.689990\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.689990\n",
      "Epoch #700    Loss: 0.427708    Train Accuracy: 0.781250    Val accuracy: 0.740692\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.740692\n",
      "Epoch #800    Loss: 0.648185    Train Accuracy: 0.687500    Val accuracy: 0.726930\n",
      "Epoch #900    Loss: 0.679377    Train Accuracy: 0.593750    Val accuracy: 0.728958\n",
      "Epoch #1000    Loss: 0.501437    Train Accuracy: 0.750000    Val accuracy: 0.723309\n",
      "Epoch #1100    Loss: 0.468319    Train Accuracy: 0.781250    Val accuracy: 0.348834\n",
      "Epoch #1200    Loss: 0.618661    Train Accuracy: 0.750000    Val accuracy: 0.304650\n",
      "Epoch #1300    Loss: 0.337178    Train Accuracy: 0.968750    Val accuracy: 0.645951\n",
      "Epoch #1400    Loss: 0.414523    Train Accuracy: 0.843750    Val accuracy: 0.704187\n",
      "Epoch #1500    Loss: 0.428558    Train Accuracy: 0.812500    Val accuracy: 0.672606\n",
      "Epoch #1600    Loss: 0.448690    Train Accuracy: 0.781250    Val accuracy: 0.726785\n",
      "Epoch #1700    Loss: 0.560152    Train Accuracy: 0.718750    Val accuracy: 0.716645\n",
      "Epoch #1800    Loss: 0.516421    Train Accuracy: 0.750000    Val accuracy: 0.732580\n",
      "Epoch #1900    Loss: 0.452250    Train Accuracy: 0.875000    Val accuracy: 0.685789\n",
      "Epoch #2000    Loss: 0.475581    Train Accuracy: 0.750000    Val accuracy: 0.735622\n",
      "Epoch #2100    Loss: 0.529585    Train Accuracy: 0.718750    Val accuracy: 0.711430\n",
      "Epoch #2200    Loss: 0.394222    Train Accuracy: 0.875000    Val accuracy: 0.735332\n",
      "Epoch #2300    Loss: 0.450622    Train Accuracy: 0.781250    Val accuracy: 0.741996\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.741996\n",
      "Epoch #2400    Loss: 0.392836    Train Accuracy: 0.875000    Val accuracy: 0.564682\n",
      "Epoch #2500    Loss: 0.416576    Train Accuracy: 0.812500    Val accuracy: 0.611473\n",
      "Epoch #2600    Loss: 0.618002    Train Accuracy: 0.781250    Val accuracy: 0.604085\n",
      "Epoch #2700    Loss: 0.513306    Train Accuracy: 0.781250    Val accuracy: 0.723598\n",
      "Epoch #2800    Loss: 0.247331    Train Accuracy: 0.906250    Val accuracy: 0.729828\n",
      "Epoch #2900    Loss: 0.644642    Train Accuracy: 0.812500    Val accuracy: 0.664783\n",
      "Epoch #3000    Loss: 0.530150    Train Accuracy: 0.718750    Val accuracy: 0.687672\n",
      "Epoch #3100    Loss: 0.489187    Train Accuracy: 0.718750    Val accuracy: 0.680284\n",
      "Epoch #3200    Loss: 0.414085    Train Accuracy: 0.812500    Val accuracy: 0.759525\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.759525\n",
      "Epoch #3300    Loss: 0.468788    Train Accuracy: 0.843750    Val accuracy: 0.696798\n",
      "Epoch #3400    Loss: 0.526442    Train Accuracy: 0.812500    Val accuracy: 0.684920\n",
      "Epoch #3500    Loss: 0.522992    Train Accuracy: 0.843750    Val accuracy: 0.730117\n",
      "Epoch #3600    Loss: 0.217754    Train Accuracy: 0.906250    Val accuracy: 0.747791\n",
      "Epoch #3700    Loss: 0.774958    Train Accuracy: 0.718750    Val accuracy: 0.632623\n",
      "Epoch #3800    Loss: 0.615879    Train Accuracy: 0.750000    Val accuracy: 0.606258\n",
      "Epoch #3900    Loss: 0.176884    Train Accuracy: 0.937500    Val accuracy: 0.653049\n",
      "Epoch #4000    Loss: 0.612981    Train Accuracy: 0.718750    Val accuracy: 0.751847\n",
      "Epoch #4100    Loss: 0.381265    Train Accuracy: 0.843750    Val accuracy: 0.747936\n",
      "Epoch #4200    Loss: 0.458843    Train Accuracy: 0.875000    Val accuracy: 0.722440\n",
      "Epoch #4300    Loss: 0.351517    Train Accuracy: 0.875000    Val accuracy: 0.710850\n",
      "Epoch #4400    Loss: 0.317213    Train Accuracy: 0.875000    Val accuracy: 0.724178\n",
      "Epoch #4500    Loss: 0.281227    Train Accuracy: 0.875000    Val accuracy: 0.633058\n",
      "Epoch #4600    Loss: 0.357580    Train Accuracy: 0.843750    Val accuracy: 0.748805\n",
      "Epoch #4700    Loss: 0.356581    Train Accuracy: 0.812500    Val accuracy: 0.757207\n",
      "Epoch #4800    Loss: 0.379389    Train Accuracy: 0.781250    Val accuracy: 0.776329\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.776329\n",
      "Epoch #4900    Loss: 0.333161    Train Accuracy: 0.875000    Val accuracy: 0.757352\n",
      "Epoch #5000    Loss: 0.251553    Train Accuracy: 0.906250    Val accuracy: 0.741996\n",
      "Epoch #5100    Loss: 0.419713    Train Accuracy: 0.812500    Val accuracy: 0.786325\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.786325\n",
      "Epoch #5200    Loss: 0.388590    Train Accuracy: 0.906250    Val accuracy: 0.622628\n",
      "Epoch #5300    Loss: 0.241812    Train Accuracy: 0.937500    Val accuracy: 0.753296\n",
      "Epoch #5400    Loss: 0.299464    Train Accuracy: 0.843750    Val accuracy: 0.758801\n",
      "Epoch #5500    Loss: 0.340218    Train Accuracy: 0.843750    Val accuracy: 0.788643\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model of accuracy 0.788643\n",
      "Epoch #5600    Loss: 0.326227    Train Accuracy: 0.875000    Val accuracy: 0.774736\n",
      "Epoch #5700    Loss: 0.260302    Train Accuracy: 0.843750    Val accuracy: 0.766333\n",
      "Epoch #5800    Loss: 0.352231    Train Accuracy: 0.781250    Val accuracy: 0.712444\n",
      "Epoch #5900    Loss: 0.559363    Train Accuracy: 0.718750    Val accuracy: 0.737361\n",
      "Epoch #6000    Loss: 0.689658    Train Accuracy: 0.687500    Val accuracy: 0.771404\n",
      "Epoch #6100    Loss: 0.178359    Train Accuracy: 1.000000    Val accuracy: 0.776184\n",
      "Epoch #6200    Loss: 0.646314    Train Accuracy: 0.718750    Val accuracy: 0.716065\n",
      "Epoch #6300    Loss: 0.721760    Train Accuracy: 0.750000    Val accuracy: 0.737940\n",
      "Epoch #6400    Loss: 0.414267    Train Accuracy: 0.843750    Val accuracy: 0.719687\n",
      "Epoch #6500    Loss: 0.165183    Train Accuracy: 0.968750    Val accuracy: 0.778647\n",
      "Epoch #6600    Loss: 0.290707    Train Accuracy: 0.875000    Val accuracy: 0.661162\n",
      "Epoch #6700    Loss: 0.249332    Train Accuracy: 0.937500    Val accuracy: 0.777633\n",
      "Epoch #6800    Loss: 0.269403    Train Accuracy: 0.937500    Val accuracy: 0.786904\n",
      "Epoch #6900    Loss: 0.165563    Train Accuracy: 0.968750    Val accuracy: 0.722295\n",
      "Epoch #7000    Loss: 0.411843    Train Accuracy: 0.875000    Val accuracy: 0.761408\n",
      "Epoch #7100    Loss: 0.259282    Train Accuracy: 0.843750    Val accuracy: 0.797479\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.797479\n",
      "Epoch #7200    Loss: 0.366078    Train Accuracy: 0.843750    Val accuracy: 0.802260\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.802260\n",
      "Epoch #7300    Loss: 0.224502    Train Accuracy: 0.906250    Val accuracy: 0.763581\n",
      "Epoch #7400    Loss: 0.157159    Train Accuracy: 0.968750    Val accuracy: 0.752861\n",
      "Epoch #7500    Loss: 0.269096    Train Accuracy: 0.906250    Val accuracy: 0.792264\n",
      "Epoch #7600    Loss: 0.246523    Train Accuracy: 0.906250    Val accuracy: 0.702303\n",
      "Epoch #7700    Loss: 0.180967    Train Accuracy: 0.906250    Val accuracy: 0.777488\n",
      "Epoch #7800    Loss: 0.350113    Train Accuracy: 0.843750    Val accuracy: 0.810517\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.810517\n",
      "Epoch #7900    Loss: 0.691060    Train Accuracy: 0.812500    Val accuracy: 0.785890\n",
      "Epoch #8000    Loss: 0.539115    Train Accuracy: 0.906250    Val accuracy: 0.758076\n",
      "Epoch #8200    Loss: 0.369774    Train Accuracy: 0.812500    Val accuracy: 0.806026\n",
      "Epoch #8300    Loss: 0.396250    Train Accuracy: 0.843750    Val accuracy: 0.797769\n",
      "Epoch #8400    Loss: 0.310430    Train Accuracy: 0.875000    Val accuracy: 0.708098\n",
      "Epoch #8500    Loss: 0.182524    Train Accuracy: 0.937500    Val accuracy: 0.813849\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.813849\n",
      "Epoch #8600    Loss: 0.199127    Train Accuracy: 0.906250    Val accuracy: 0.807475\n",
      "Epoch #8700    Loss: 0.318693    Train Accuracy: 0.875000    Val accuracy: 0.754165\n",
      "Epoch #8800    Loss: 0.150929    Train Accuracy: 0.968750    Val accuracy: 0.812256\n",
      "Epoch #8900    Loss: 0.267643    Train Accuracy: 0.875000    Val accuracy: 0.791105\n",
      "Epoch #9000    Loss: 0.210638    Train Accuracy: 0.968750    Val accuracy: 0.785021\n",
      "Epoch #9100    Loss: 0.510105    Train Accuracy: 0.750000    Val accuracy: 0.769231\n",
      "Epoch #9200    Loss: 0.558190    Train Accuracy: 0.750000    Val accuracy: 0.651890\n",
      "Epoch #9300    Loss: 0.252055    Train Accuracy: 0.875000    Val accuracy: 0.823265\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.823265\n",
      "Epoch #9400    Loss: 0.208375    Train Accuracy: 0.937500    Val accuracy: 0.784297\n",
      "Epoch #9500    Loss: 0.293106    Train Accuracy: 0.843750    Val accuracy: 0.806461\n",
      "Epoch #9600    Loss: 0.377585    Train Accuracy: 0.906250    Val accuracy: 0.777633\n",
      "Epoch #9700    Loss: 0.263621    Train Accuracy: 0.906250    Val accuracy: 0.759525\n",
      "Epoch #9800    Loss: 0.204958    Train Accuracy: 0.968750    Val accuracy: 0.822831\n",
      "Epoch #9900    Loss: 0.197074    Train Accuracy: 0.875000    Val accuracy: 0.804723\n",
      "Epoch #10000    Loss: 0.175671    Train Accuracy: 0.968750    Val accuracy: 0.781110\n",
      "Epoch #10100    Loss: 0.244549    Train Accuracy: 0.875000    Val accuracy: 0.834999\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.834999\n",
      "Epoch #10200    Loss: 0.239106    Train Accuracy: 0.843750    Val accuracy: 0.810517\n",
      "Epoch #10300    Loss: 0.240306    Train Accuracy: 0.906250    Val accuracy: 0.735043\n",
      "Epoch #10400    Loss: 0.265185    Train Accuracy: 0.843750    Val accuracy: 0.827177\n",
      "Epoch #10500    Loss: 0.284125    Train Accuracy: 0.843750    Val accuracy: 0.673186\n",
      "Epoch #10600    Loss: 0.268783    Train Accuracy: 0.906250    Val accuracy: 0.784876\n",
      "Epoch #10700    Loss: 0.396018    Train Accuracy: 0.812500    Val accuracy: 0.784876\n",
      "Epoch #10800    Loss: 0.482691    Train Accuracy: 0.843750    Val accuracy: 0.811241\n",
      "Epoch #10900    Loss: 0.210110    Train Accuracy: 0.875000    Val accuracy: 0.826597\n",
      "Epoch #11000    Loss: 0.294005    Train Accuracy: 0.906250    Val accuracy: 0.820803\n",
      "Epoch #11100    Loss: 0.353320    Train Accuracy: 0.875000    Val accuracy: 0.751123\n",
      "Epoch #11200    Loss: 0.229245    Train Accuracy: 0.937500    Val accuracy: 0.816601\n",
      "Epoch #11300    Loss: 0.230392    Train Accuracy: 0.875000    Val accuracy: 0.790960\n",
      "Epoch #11400    Loss: 0.130681    Train Accuracy: 0.937500    Val accuracy: 0.835579\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.835579\n",
      "Epoch #11500    Loss: 0.240832    Train Accuracy: 0.937500    Val accuracy: 0.801391\n",
      "Epoch #11600    Loss: 0.353756    Train Accuracy: 0.875000    Val accuracy: 0.819933\n",
      "Epoch #11700    Loss: 0.330264    Train Accuracy: 0.843750    Val accuracy: 0.776764\n",
      "Epoch #11800    Loss: 0.178847    Train Accuracy: 0.937500    Val accuracy: 0.834130\n",
      "Epoch #11900    Loss: 0.429222    Train Accuracy: 0.875000    Val accuracy: 0.807475\n",
      "Epoch #12000    Loss: 0.182074    Train Accuracy: 0.937500    Val accuracy: 0.820658\n",
      "Epoch #12100    Loss: 0.335932    Train Accuracy: 0.906250    Val accuracy: 0.787773\n",
      "Epoch #12200    Loss: 0.279929    Train Accuracy: 0.875000    Val accuracy: 0.809793\n",
      "Epoch #12300    Loss: 0.078227    Train Accuracy: 0.968750    Val accuracy: 0.827177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12400    Loss: 0.087133    Train Accuracy: 0.968750    Val accuracy: 0.834565\n",
      "Epoch #12500    Loss: 0.257868    Train Accuracy: 0.906250    Val accuracy: 0.832826\n",
      "Epoch #12600    Loss: 0.207420    Train Accuracy: 0.906250    Val accuracy: 0.713458\n",
      "Epoch #12700    Loss: 0.062970    Train Accuracy: 1.000000    Val accuracy: 0.810227\n",
      "Epoch #12800    Loss: 0.159016    Train Accuracy: 0.968750    Val accuracy: 0.833551\n",
      "Epoch #12900    Loss: 0.169565    Train Accuracy: 0.906250    Val accuracy: 0.794582\n",
      "Epoch #13000    Loss: 0.320837    Train Accuracy: 0.875000    Val accuracy: 0.778212\n",
      "Epoch #13100    Loss: 0.486204    Train Accuracy: 0.843750    Val accuracy: 0.765899\n",
      "Epoch #13200    Loss: 0.229495    Train Accuracy: 0.906250    Val accuracy: 0.818340\n",
      "Epoch #13300    Loss: 0.268853    Train Accuracy: 0.843750    Val accuracy: 0.768651\n",
      "Epoch #13400    Loss: 0.219246    Train Accuracy: 0.906250    Val accuracy: 0.762132\n",
      "Epoch #13500    Loss: 0.176623    Train Accuracy: 0.906250    Val accuracy: 0.785311\n",
      "Epoch #13600    Loss: 0.155150    Train Accuracy: 0.937500    Val accuracy: 0.833551\n",
      "Epoch #13700    Loss: 0.282570    Train Accuracy: 0.843750    Val accuracy: 0.824714\n",
      "Epoch #13800    Loss: 0.319068    Train Accuracy: 0.843750    Val accuracy: 0.796176\n",
      "Epoch #13900    Loss: 0.226988    Train Accuracy: 0.875000    Val accuracy: 0.838621\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.838621\n",
      "Epoch #14000    Loss: 0.525248    Train Accuracy: 0.812500    Val accuracy: 0.826018\n",
      "Epoch #14100    Loss: 0.199286    Train Accuracy: 0.906250    Val accuracy: 0.831088\n",
      "Epoch #14200    Loss: 0.311343    Train Accuracy: 0.843750    Val accuracy: 0.785166\n",
      "Epoch #14300    Loss: 0.317689    Train Accuracy: 0.875000    Val accuracy: 0.794292\n",
      "Epoch #14400    Loss: 0.701215    Train Accuracy: 0.781250    Val accuracy: 0.795741\n",
      "Epoch #14500    Loss: 0.184028    Train Accuracy: 0.937500    Val accuracy: 0.793423\n",
      "Epoch #14600    Loss: 0.248334    Train Accuracy: 0.875000    Val accuracy: 0.834420\n",
      "Epoch #14700    Loss: 0.417329    Train Accuracy: 0.875000    Val accuracy: 0.796465\n",
      "Epoch #14800    Loss: 0.301602    Train Accuracy: 0.843750    Val accuracy: 0.797334\n",
      "Epoch #14900    Loss: 0.196940    Train Accuracy: 0.843750    Val accuracy: 0.788498\n",
      "Epoch #15000    Loss: 0.209442    Train Accuracy: 0.906250    Val accuracy: 0.843981\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.843981\n",
      "Epoch #15100    Loss: 0.278824    Train Accuracy: 0.875000    Val accuracy: 0.812111\n",
      "Epoch #15200    Loss: 0.286642    Train Accuracy: 0.937500    Val accuracy: 0.803998\n",
      "Epoch #15300    Loss: 0.194024    Train Accuracy: 0.906250    Val accuracy: 0.832681\n",
      "Epoch #15400    Loss: 0.357132    Train Accuracy: 0.812500    Val accuracy: 0.767348\n",
      "Epoch #15500    Loss: 0.174546    Train Accuracy: 0.906250    Val accuracy: 0.832681\n",
      "Epoch #15600    Loss: 0.277447    Train Accuracy: 0.875000    Val accuracy: 0.756772\n",
      "Epoch #15700    Loss: 0.383966    Train Accuracy: 0.875000    Val accuracy: 0.802405\n",
      "Epoch #15800    Loss: 0.142128    Train Accuracy: 0.968750    Val accuracy: 0.753875\n",
      "Epoch #15900    Loss: 0.241981    Train Accuracy: 0.843750    Val accuracy: 0.736347\n",
      "Epoch #16000    Loss: 0.184579    Train Accuracy: 0.906250    Val accuracy: 0.817036\n",
      "Epoch #16100    Loss: 0.116008    Train Accuracy: 0.906250    Val accuracy: 0.806026\n",
      "Epoch #16200    Loss: 0.157517    Train Accuracy: 0.968750    Val accuracy: 0.834854\n",
      "Epoch #16300    Loss: 0.184314    Train Accuracy: 0.906250    Val accuracy: 0.793858\n",
      "Epoch #16400    Loss: 0.303966    Train Accuracy: 0.968750    Val accuracy: 0.731856\n",
      "Epoch #16500    Loss: 0.160643    Train Accuracy: 0.968750    Val accuracy: 0.813125\n",
      "Epoch #16600    Loss: 0.085618    Train Accuracy: 1.000000    Val accuracy: 0.812256\n",
      "Epoch #16700    Loss: 0.284527    Train Accuracy: 0.906250    Val accuracy: 0.813559\n",
      "Epoch #16800    Loss: 0.314372    Train Accuracy: 0.875000    Val accuracy: 0.738085\n",
      "Epoch #16900    Loss: 0.100881    Train Accuracy: 1.000000    Val accuracy: 0.759815\n",
      "Epoch #17000    Loss: 0.176994    Train Accuracy: 0.968750    Val accuracy: 0.815732\n",
      "Epoch #17100    Loss: 0.157801    Train Accuracy: 0.968750    Val accuracy: 0.816601\n",
      "Epoch #17200    Loss: 0.232760    Train Accuracy: 0.875000    Val accuracy: 0.806026\n",
      "Epoch #17300    Loss: 0.154003    Train Accuracy: 0.937500    Val accuracy: 0.837462\n",
      "Epoch #17400    Loss: 0.501085    Train Accuracy: 0.875000    Val accuracy: 0.742431\n",
      "Epoch #17500    Loss: 0.229769    Train Accuracy: 0.906250    Val accuracy: 0.792844\n",
      "Epoch #17600    Loss: 0.211630    Train Accuracy: 0.937500    Val accuracy: 0.840794\n",
      "Epoch #17700    Loss: 0.085825    Train Accuracy: 1.000000    Val accuracy: 0.825583\n",
      "Epoch #17800    Loss: 0.236326    Train Accuracy: 0.937500    Val accuracy: 0.840504\n",
      "Epoch #17900    Loss: 0.097237    Train Accuracy: 1.000000    Val accuracy: 0.779516\n",
      "Epoch #18000    Loss: 0.120718    Train Accuracy: 0.937500    Val accuracy: 0.805447\n",
      "Epoch #18100    Loss: 0.175069    Train Accuracy: 0.937500    Val accuracy: 0.831812\n",
      "Epoch #18200    Loss: 0.265951    Train Accuracy: 0.875000    Val accuracy: 0.824569\n",
      "Epoch #18300    Loss: 0.245306    Train Accuracy: 0.875000    Val accuracy: 0.799652\n",
      "Epoch #18400    Loss: 0.411116    Train Accuracy: 0.843750    Val accuracy: 0.758076\n",
      "Epoch #18500    Loss: 0.035956    Train Accuracy: 1.000000    Val accuracy: 0.817326\n",
      "Epoch #18600    Loss: 0.074657    Train Accuracy: 1.000000    Val accuracy: 0.761408\n",
      "Epoch #18700    Loss: 0.356450    Train Accuracy: 0.843750    Val accuracy: 0.853832\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "Save model of accuracy 0.853832\n",
      "Epoch #18800    Loss: 0.161761    Train Accuracy: 0.937500    Val accuracy: 0.842822\n",
      "Epoch #18900    Loss: 0.118390    Train Accuracy: 1.000000    Val accuracy: 0.827756\n",
      "Epoch #19000    Loss: 0.198386    Train Accuracy: 0.906250    Val accuracy: 0.772852\n",
      "Epoch #19100    Loss: 0.199148    Train Accuracy: 0.906250    Val accuracy: 0.794872\n",
      "Epoch #19200    Loss: 0.112793    Train Accuracy: 0.968750    Val accuracy: 0.793278\n",
      "Epoch #19300    Loss: 0.139341    Train Accuracy: 0.968750    Val accuracy: 0.827321\n",
      "Epoch #19400    Loss: 0.131382    Train Accuracy: 0.937500    Val accuracy: 0.837897\n",
      "Epoch #19500    Loss: 0.143953    Train Accuracy: 0.875000    Val accuracy: 0.710126\n",
      "Epoch #19600    Loss: 0.321924    Train Accuracy: 0.906250    Val accuracy: 0.749095\n",
      "Epoch #19700    Loss: 0.250762    Train Accuracy: 0.937500    Val accuracy: 0.815732\n",
      "Epoch #19800    Loss: 0.195214    Train Accuracy: 0.937500    Val accuracy: 0.697523\n",
      "Epoch #19900    Loss: 0.208090    Train Accuracy: 0.906250    Val accuracy: 0.793278\n",
      "Epoch #20000    Loss: 0.289342    Train Accuracy: 0.906250    Val accuracy: 0.818485\n",
      "Epoch #20100    Loss: 0.192073    Train Accuracy: 0.906250    Val accuracy: 0.805012\n",
      "Epoch #20200    Loss: 0.216247    Train Accuracy: 0.843750    Val accuracy: 0.832681\n",
      "Epoch #20300    Loss: 0.285495    Train Accuracy: 0.906250    Val accuracy: 0.747501\n",
      "Epoch #20400    Loss: 0.154218    Train Accuracy: 0.968750    Val accuracy: 0.713168\n",
      "Epoch #20500    Loss: 0.173407    Train Accuracy: 0.937500    Val accuracy: 0.840939\n",
      "Epoch #20600    Loss: 0.144190    Train Accuracy: 0.937500    Val accuracy: 0.727220\n",
      "Epoch #20700    Loss: 0.481950    Train Accuracy: 0.875000    Val accuracy: 0.813849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20800    Loss: 0.143519    Train Accuracy: 0.937500    Val accuracy: 0.804578\n",
      "Epoch #20900    Loss: 0.260051    Train Accuracy: 0.937500    Val accuracy: 0.838186\n",
      "Epoch #21000    Loss: 0.282844    Train Accuracy: 0.875000    Val accuracy: 0.751268\n",
      "Epoch #21100    Loss: 0.186459    Train Accuracy: 0.937500    Val accuracy: 0.817181\n",
      "Epoch #21200    Loss: 0.194128    Train Accuracy: 0.937500    Val accuracy: 0.783572\n",
      "Epoch #21300    Loss: 0.250073    Train Accuracy: 0.906250    Val accuracy: 0.814863\n",
      "Epoch #21400    Loss: 0.077466    Train Accuracy: 1.000000    Val accuracy: 0.773866\n",
      "Epoch #21500    Loss: 0.101442    Train Accuracy: 0.968750    Val accuracy: 0.790816\n",
      "Epoch #21600    Loss: 0.354961    Train Accuracy: 0.843750    Val accuracy: 0.810372\n",
      "Epoch #21700    Loss: 0.298818    Train Accuracy: 0.843750    Val accuracy: 0.812545\n",
      "Epoch #21800    Loss: 0.164934    Train Accuracy: 0.937500    Val accuracy: 0.817616\n",
      "Epoch #21900    Loss: 0.146279    Train Accuracy: 0.937500    Val accuracy: 0.794437\n",
      "Epoch #22000    Loss: 0.197199    Train Accuracy: 0.937500    Val accuracy: 0.827321\n",
      "Epoch #22100    Loss: 0.136942    Train Accuracy: 0.937500    Val accuracy: 0.805302\n",
      "Epoch #22200    Loss: 0.115929    Train Accuracy: 0.906250    Val accuracy: 0.815877\n",
      "Epoch #22300    Loss: 0.123403    Train Accuracy: 0.968750    Val accuracy: 0.822541\n",
      "Epoch #22400    Loss: 0.137693    Train Accuracy: 0.937500    Val accuracy: 0.838186\n",
      "Epoch #22500    Loss: 0.248563    Train Accuracy: 0.875000    Val accuracy: 0.783138\n",
      "Epoch #22600    Loss: 0.353444    Train Accuracy: 0.843750    Val accuracy: 0.819209\n",
      "Epoch #22700    Loss: 0.350966    Train Accuracy: 0.906250    Val accuracy: 0.809503\n",
      "Epoch #22800    Loss: 0.250427    Train Accuracy: 0.875000    Val accuracy: 0.792699\n",
      "Epoch #22900    Loss: 0.153931    Train Accuracy: 0.968750    Val accuracy: 0.817036\n",
      "Epoch #23000    Loss: 0.163065    Train Accuracy: 0.937500    Val accuracy: 0.817905\n",
      "Epoch #23100    Loss: 0.111708    Train Accuracy: 0.937500    Val accuracy: 0.801970\n",
      "Epoch #23200    Loss: 0.151014    Train Accuracy: 0.937500    Val accuracy: 0.775315\n",
      "Epoch #23300    Loss: 0.076562    Train Accuracy: 0.968750    Val accuracy: 0.782269\n",
      "Epoch #23400    Loss: 0.155234    Train Accuracy: 0.937500    Val accuracy: 0.782413\n",
      "Epoch #23500    Loss: 0.245101    Train Accuracy: 0.875000    Val accuracy: 0.812980\n",
      "Epoch #23600    Loss: 0.181620    Train Accuracy: 0.968750    Val accuracy: 0.808054\n",
      "Epoch #23700    Loss: 0.188250    Train Accuracy: 0.906250    Val accuracy: 0.831088\n",
      "Epoch #23800    Loss: 0.102641    Train Accuracy: 0.968750    Val accuracy: 0.840070\n",
      "Epoch #23900    Loss: 0.356773    Train Accuracy: 0.906250    Val accuracy: 0.805157\n",
      "Epoch #24000    Loss: 0.107799    Train Accuracy: 0.968750    Val accuracy: 0.821382\n",
      "Epoch #24100    Loss: 0.072695    Train Accuracy: 1.000000    Val accuracy: 0.806751\n",
      "Epoch #24200    Loss: 0.291602    Train Accuracy: 0.843750    Val accuracy: 0.826597\n",
      "Epoch #24300    Loss: 0.149707    Train Accuracy: 0.937500    Val accuracy: 0.803274\n",
      "Epoch #24400    Loss: 0.260813    Train Accuracy: 0.875000    Val accuracy: 0.782124\n",
      "Epoch #24500    Loss: 0.115213    Train Accuracy: 0.968750    Val accuracy: 0.826163\n",
      "Epoch #24600    Loss: 0.137022    Train Accuracy: 0.937500    Val accuracy: 0.783283\n",
      "Epoch #24700    Loss: 0.130663    Train Accuracy: 0.906250    Val accuracy: 0.833261\n",
      "Epoch #24800    Loss: 0.313528    Train Accuracy: 0.937500    Val accuracy: 0.819064\n",
      "Epoch #24900    Loss: 0.086889    Train Accuracy: 0.937500    Val accuracy: 0.822106\n",
      "Epoch #25000    Loss: 0.174135    Train Accuracy: 0.937500    Val accuracy: 0.832971\n",
      "Epoch #25100    Loss: 0.224197    Train Accuracy: 0.937500    Val accuracy: 0.821961\n",
      "Epoch #25200    Loss: 0.751702    Train Accuracy: 0.812500    Val accuracy: 0.798204\n",
      "Epoch #25300    Loss: 0.164634    Train Accuracy: 0.937500    Val accuracy: 0.816601\n",
      "Epoch #25400    Loss: 0.160268    Train Accuracy: 0.906250    Val accuracy: 0.790526\n",
      "Epoch #25500    Loss: 0.166108    Train Accuracy: 0.937500    Val accuracy: 0.805882\n",
      "Epoch #25600    Loss: 0.335001    Train Accuracy: 0.781250    Val accuracy: 0.818050\n",
      "Epoch #25700    Loss: 0.262848    Train Accuracy: 0.875000    Val accuracy: 0.784297\n",
      "Epoch #25800    Loss: 0.221523    Train Accuracy: 0.812500    Val accuracy: 0.785890\n",
      "Epoch #25900    Loss: 0.079013    Train Accuracy: 0.968750    Val accuracy: 0.757786\n",
      "Epoch #26000    Loss: 0.211044    Train Accuracy: 0.937500    Val accuracy: 0.775315\n",
      "Epoch #26100    Loss: 0.110549    Train Accuracy: 0.937500    Val accuracy: 0.801536\n",
      "Epoch #26200    Loss: 0.198805    Train Accuracy: 0.906250    Val accuracy: 0.803853\n",
      "Epoch #26300    Loss: 0.096628    Train Accuracy: 1.000000    Val accuracy: 0.780820\n",
      "Epoch #26400    Loss: 0.077023    Train Accuracy: 0.968750    Val accuracy: 0.772273\n",
      "Epoch #26500    Loss: 0.111901    Train Accuracy: 0.968750    Val accuracy: 0.821237\n",
      "Epoch #26600    Loss: 0.176729    Train Accuracy: 0.906250    Val accuracy: 0.842677\n",
      "Epoch #26700    Loss: 0.116121    Train Accuracy: 0.968750    Val accuracy: 0.792409\n",
      "Epoch #26800    Loss: 0.081598    Train Accuracy: 1.000000    Val accuracy: 0.805737\n",
      "Epoch #26900    Loss: 0.137118    Train Accuracy: 0.937500    Val accuracy: 0.833840\n",
      "Epoch #27000    Loss: 0.222627    Train Accuracy: 0.937500    Val accuracy: 0.825004\n",
      "Epoch #27100    Loss: 0.242895    Train Accuracy: 0.937500    Val accuracy: 0.782848\n",
      "Epoch #27200    Loss: 0.061554    Train Accuracy: 1.000000    Val accuracy: 0.812835\n",
      "Epoch #27300    Loss: 0.152011    Train Accuracy: 0.937500    Val accuracy: 0.838041\n",
      "Epoch #27400    Loss: 0.278521    Train Accuracy: 0.843750    Val accuracy: 0.782124\n",
      "Epoch #27500    Loss: 0.275289    Train Accuracy: 0.937500    Val accuracy: 0.748225\n",
      "Epoch #27600    Loss: 0.150010    Train Accuracy: 0.968750    Val accuracy: 0.749384\n",
      "Epoch #27700    Loss: 0.251240    Train Accuracy: 0.875000    Val accuracy: 0.796755\n",
      "Epoch #27800    Loss: 0.173792    Train Accuracy: 0.968750    Val accuracy: 0.847168\n",
      "Epoch #27900    Loss: 0.143944    Train Accuracy: 0.937500    Val accuracy: 0.801536\n",
      "Epoch #28000    Loss: 0.126298    Train Accuracy: 0.968750    Val accuracy: 0.800666\n",
      "Epoch #28100    Loss: 0.125654    Train Accuracy: 0.937500    Val accuracy: 0.815153\n",
      "Epoch #28200    Loss: 0.098838    Train Accuracy: 1.000000    Val accuracy: 0.769955\n",
      "Epoch #28300    Loss: 0.167689    Train Accuracy: 0.968750    Val accuracy: 0.796465\n",
      "Epoch #28400    Loss: 0.127873    Train Accuracy: 0.968750    Val accuracy: 0.799507\n",
      "Epoch #28500    Loss: 0.178202    Train Accuracy: 0.906250    Val accuracy: 0.761553\n",
      "Epoch #28600    Loss: 0.103844    Train Accuracy: 0.968750    Val accuracy: 0.802550\n",
      "Epoch #28700    Loss: 0.214512    Train Accuracy: 0.937500    Val accuracy: 0.835144\n",
      "Epoch #28800    Loss: 0.064783    Train Accuracy: 0.968750    Val accuracy: 0.783138\n",
      "Epoch #28900    Loss: 0.093128    Train Accuracy: 0.968750    Val accuracy: 0.794582\n",
      "Epoch #29000    Loss: 0.140661    Train Accuracy: 0.937500    Val accuracy: 0.827177\n",
      "Epoch #29100    Loss: 0.130049    Train Accuracy: 0.968750    Val accuracy: 0.841663\n",
      "Epoch #29200    Loss: 0.334194    Train Accuracy: 0.843750    Val accuracy: 0.789077\n",
      "Epoch #29300    Loss: 0.262417    Train Accuracy: 0.937500    Val accuracy: 0.810952\n",
      "Epoch #29400    Loss: 0.157624    Train Accuracy: 0.937500    Val accuracy: 0.725047\n",
      "Epoch #29500    Loss: 0.323680    Train Accuracy: 0.937500    Val accuracy: 0.804578\n",
      "Epoch #29600    Loss: 0.223948    Train Accuracy: 0.906250    Val accuracy: 0.796610\n",
      "Epoch #29700    Loss: 0.205937    Train Accuracy: 0.906250    Val accuracy: 0.766333\n",
      "Epoch #29800    Loss: 0.107249    Train Accuracy: 0.937500    Val accuracy: 0.838331\n",
      "Epoch #29900    Loss: 0.140897    Train Accuracy: 0.937500    Val accuracy: 0.752861\n",
      "Epoch #30000    Loss: 0.145718    Train Accuracy: 0.937500    Val accuracy: 0.807910\n",
      "Epoch #30100    Loss: 0.176388    Train Accuracy: 0.937500    Val accuracy: 0.802984\n",
      "Epoch #30200    Loss: 0.053319    Train Accuracy: 1.000000    Val accuracy: 0.716355\n",
      "Epoch #30300    Loss: 0.161159    Train Accuracy: 0.937500    Val accuracy: 0.802405\n",
      "Epoch #30400    Loss: 0.128798    Train Accuracy: 0.937500    Val accuracy: 0.803998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #30500    Loss: 0.058968    Train Accuracy: 1.000000    Val accuracy: 0.796755\n",
      "Epoch #30600    Loss: 0.172803    Train Accuracy: 0.937500    Val accuracy: 0.829639\n",
      "Epoch #30700    Loss: 0.186749    Train Accuracy: 0.906250    Val accuracy: 0.784586\n",
      "Epoch #30800    Loss: 0.153600    Train Accuracy: 0.937500    Val accuracy: 0.828480\n",
      "Epoch #30900    Loss: 0.259937    Train Accuracy: 0.843750    Val accuracy: 0.825004\n",
      "Epoch #31000    Loss: 0.123882    Train Accuracy: 0.937500    Val accuracy: 0.788063\n",
      "Epoch #31100    Loss: 0.115052    Train Accuracy: 0.937500    Val accuracy: 0.786470\n",
      "Epoch #31200    Loss: 0.083645    Train Accuracy: 0.968750    Val accuracy: 0.791105\n",
      "Epoch #31300    Loss: 0.324557    Train Accuracy: 0.937500    Val accuracy: 0.760104\n",
      "Epoch #31400    Loss: 0.289749    Train Accuracy: 0.906250    Val accuracy: 0.786470\n",
      "Epoch #31500    Loss: 0.056095    Train Accuracy: 1.000000    Val accuracy: 0.807765\n",
      "Epoch #31600    Loss: 0.133428    Train Accuracy: 0.906250    Val accuracy: 0.826163\n",
      "Epoch #31700    Loss: 0.096949    Train Accuracy: 0.968750    Val accuracy: 0.813559\n",
      "Epoch #31800    Loss: 0.092254    Train Accuracy: 0.968750    Val accuracy: 0.806316\n",
      "Epoch #31900    Loss: 0.392897    Train Accuracy: 0.906250    Val accuracy: 0.827321\n",
      "Epoch #32000    Loss: 0.213440    Train Accuracy: 0.875000    Val accuracy: 0.767492\n",
      "Epoch #32100    Loss: 0.179987    Train Accuracy: 0.906250    Val accuracy: 0.837027\n",
      "Epoch #32200    Loss: 0.091643    Train Accuracy: 0.937500    Val accuracy: 0.781110\n",
      "Epoch #32300    Loss: 0.099771    Train Accuracy: 0.968750    Val accuracy: 0.784442\n",
      "Epoch #32400    Loss: 0.185803    Train Accuracy: 0.968750    Val accuracy: 0.807910\n",
      "Epoch #32500    Loss: 0.126103    Train Accuracy: 0.937500    Val accuracy: 0.805737\n",
      "Epoch #32600    Loss: 0.140651    Train Accuracy: 0.937500    Val accuracy: 0.844126\n",
      "Epoch #32700    Loss: 0.053459    Train Accuracy: 0.968750    Val accuracy: 0.792554\n",
      "Epoch #32800    Loss: 0.173328    Train Accuracy: 0.937500    Val accuracy: 0.797045\n",
      "Epoch #32900    Loss: 0.109902    Train Accuracy: 0.937500    Val accuracy: 0.795162\n",
      "Epoch #33000    Loss: 0.124078    Train Accuracy: 0.968750    Val accuracy: 0.794003\n",
      "Epoch #33100    Loss: 0.178280    Train Accuracy: 0.937500    Val accuracy: 0.793713\n",
      "Epoch #33200    Loss: 0.060697    Train Accuracy: 1.000000    Val accuracy: 0.792264\n",
      "Epoch #33300    Loss: 0.159568    Train Accuracy: 0.937500    Val accuracy: 0.787339\n",
      "Epoch #33400    Loss: 0.067630    Train Accuracy: 1.000000    Val accuracy: 0.800087\n",
      "Epoch #33500    Loss: 0.169791    Train Accuracy: 0.906250    Val accuracy: 0.748225\n",
      "Epoch #33600    Loss: 0.317734    Train Accuracy: 0.812500    Val accuracy: 0.772708\n",
      "Epoch #33700    Loss: 0.544625    Train Accuracy: 0.781250    Val accuracy: 0.815732\n",
      "Epoch #33800    Loss: 0.309791    Train Accuracy: 0.906250    Val accuracy: 0.792989\n",
      "Epoch #33900    Loss: 0.225292    Train Accuracy: 0.875000    Val accuracy: 0.782703\n",
      "Epoch #34000    Loss: 0.173797    Train Accuracy: 0.906250    Val accuracy: 0.784007\n",
      "Epoch #34100    Loss: 0.199073    Train Accuracy: 0.875000    Val accuracy: 0.744314\n",
      "Epoch #34200    Loss: 0.372789    Train Accuracy: 0.812500    Val accuracy: 0.803129\n",
      "Epoch #34300    Loss: 0.336470    Train Accuracy: 0.875000    Val accuracy: 0.752137\n",
      "Epoch #34400    Loss: 0.196074    Train Accuracy: 0.937500    Val accuracy: 0.782993\n",
      "Epoch #34500    Loss: 0.231791    Train Accuracy: 0.875000    Val accuracy: 0.817616\n",
      "Epoch #34600    Loss: 0.352242    Train Accuracy: 0.843750    Val accuracy: 0.798783\n",
      "Epoch #34700    Loss: 0.069167    Train Accuracy: 1.000000    Val accuracy: 0.787049\n",
      "Epoch #34800    Loss: 0.226513    Train Accuracy: 0.906250    Val accuracy: 0.800956\n",
      "Epoch #34900    Loss: 0.089743    Train Accuracy: 1.000000    Val accuracy: 0.808344\n",
      "Epoch #35000    Loss: 0.122699    Train Accuracy: 0.937500    Val accuracy: 0.747646\n",
      "Epoch #35100    Loss: 0.200410    Train Accuracy: 0.875000    Val accuracy: 0.784152\n",
      "Epoch #35200    Loss: 0.094302    Train Accuracy: 0.968750    Val accuracy: 0.774446\n",
      "Epoch #35300    Loss: 0.198627    Train Accuracy: 0.875000    Val accuracy: 0.847168\n",
      "Epoch #35400    Loss: 0.099701    Train Accuracy: 0.937500    Val accuracy: 0.777778\n",
      "Epoch #35500    Loss: 0.232738    Train Accuracy: 0.937500    Val accuracy: 0.783427\n",
      "Epoch #35600    Loss: 0.036704    Train Accuracy: 1.000000    Val accuracy: 0.782413\n",
      "Epoch #35700    Loss: 0.191886    Train Accuracy: 0.968750    Val accuracy: 0.778647\n",
      "Epoch #35800    Loss: 0.147869    Train Accuracy: 0.968750    Val accuracy: 0.764450\n",
      "Epoch #35900    Loss: 0.066230    Train Accuracy: 0.968750    Val accuracy: 0.803564\n",
      "Epoch #36000    Loss: 0.102987    Train Accuracy: 1.000000    Val accuracy: 0.774156\n",
      "Epoch #36100    Loss: 0.166009    Train Accuracy: 0.937500    Val accuracy: 0.786325\n",
      "Epoch #36200    Loss: 0.300208    Train Accuracy: 0.906250    Val accuracy: 0.718673\n",
      "Epoch #36300    Loss: 0.191788    Train Accuracy: 0.937500    Val accuracy: 0.753585\n",
      "Epoch #36400    Loss: 0.140270    Train Accuracy: 0.937500    Val accuracy: 0.751992\n",
      "Epoch #36500    Loss: 0.111307    Train Accuracy: 0.906250    Val accuracy: 0.790236\n",
      "Epoch #36600    Loss: 0.068896    Train Accuracy: 1.000000    Val accuracy: 0.803998\n",
      "Epoch #36700    Loss: 0.061944    Train Accuracy: 1.000000    Val accuracy: 0.790381\n",
      "Epoch #36800    Loss: 0.067900    Train Accuracy: 0.968750    Val accuracy: 0.810952\n",
      "Epoch #36900    Loss: 0.098792    Train Accuracy: 0.937500    Val accuracy: 0.766478\n",
      "Epoch #37000    Loss: 0.035867    Train Accuracy: 1.000000    Val accuracy: 0.748370\n",
      "Epoch #37100    Loss: 0.154561    Train Accuracy: 0.968750    Val accuracy: 0.771838\n",
      "Epoch #37200    Loss: 0.133787    Train Accuracy: 0.906250    Val accuracy: 0.763871\n",
      "Epoch #37300    Loss: 0.169795    Train Accuracy: 0.937500    Val accuracy: 0.782703\n",
      "Epoch #37400    Loss: 0.111656    Train Accuracy: 0.937500    Val accuracy: 0.784586\n",
      "Epoch #37500    Loss: 0.124907    Train Accuracy: 0.937500    Val accuracy: 0.763291\n",
      "Epoch #37600    Loss: 0.177819    Train Accuracy: 0.875000    Val accuracy: 0.794872\n",
      "Epoch #37700    Loss: 0.264411    Train Accuracy: 0.937500    Val accuracy: 0.763436\n",
      "Epoch #37800    Loss: 0.304706    Train Accuracy: 0.906250    Val accuracy: 0.759959\n",
      "Epoch #37900    Loss: 0.326757    Train Accuracy: 0.843750    Val accuracy: 0.783572\n",
      "Epoch #38000    Loss: 0.247229    Train Accuracy: 0.843750    Val accuracy: 0.745473\n",
      "Epoch #38100    Loss: 0.161466    Train Accuracy: 0.968750    Val accuracy: 0.757352\n",
      "Epoch #38200    Loss: 0.527000    Train Accuracy: 0.875000    Val accuracy: 0.755324\n",
      "Epoch #38300    Loss: 0.147242    Train Accuracy: 0.906250    Val accuracy: 0.777198\n",
      "Epoch #38400    Loss: 0.072111    Train Accuracy: 1.000000    Val accuracy: 0.778647\n",
      "Epoch #38500    Loss: 0.115086    Train Accuracy: 1.000000    Val accuracy: 0.802115\n",
      "Epoch #38600    Loss: 0.112942    Train Accuracy: 0.968750    Val accuracy: 0.771549\n",
      "Epoch #38700    Loss: 0.082964    Train Accuracy: 0.937500    Val accuracy: 0.809213\n",
      "Epoch #38800    Loss: 0.120889    Train Accuracy: 0.875000    Val accuracy: 0.806026\n",
      "Epoch #38900    Loss: 0.287508    Train Accuracy: 0.968750    Val accuracy: 0.806751\n",
      "Epoch #39000    Loss: 0.124758    Train Accuracy: 0.906250    Val accuracy: 0.793568\n",
      "Epoch #39100    Loss: 0.085916    Train Accuracy: 0.968750    Val accuracy: 0.757786\n",
      "Epoch #39200    Loss: 0.059190    Train Accuracy: 0.968750    Val accuracy: 0.764740\n",
      "Epoch #39300    Loss: 0.062018    Train Accuracy: 1.000000    Val accuracy: 0.755324\n",
      "Epoch #39400    Loss: 0.105170    Train Accuracy: 0.937500    Val accuracy: 0.748370\n",
      "Epoch #39500    Loss: 0.269256    Train Accuracy: 0.906250    Val accuracy: 0.768796\n",
      "Epoch #39600    Loss: 0.170868    Train Accuracy: 0.937500    Val accuracy: 0.805012\n",
      "Epoch #39700    Loss: 0.246242    Train Accuracy: 0.906250    Val accuracy: 0.718094\n",
      "Epoch #39800    Loss: 0.075463    Train Accuracy: 0.968750    Val accuracy: 0.749239\n",
      "Epoch #39900    Loss: 0.048470    Train Accuracy: 0.968750    Val accuracy: 0.780965\n",
      "Epoch #40000    Loss: 0.152547    Train Accuracy: 0.937500    Val accuracy: 0.777198\n",
      "Epoch #40100    Loss: 0.064530    Train Accuracy: 1.000000    Val accuracy: 0.752137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40200    Loss: 0.063608    Train Accuracy: 0.968750    Val accuracy: 0.790381\n",
      "Epoch #40300    Loss: 0.135311    Train Accuracy: 0.937500    Val accuracy: 0.767058\n",
      "Epoch #40400    Loss: 0.118474    Train Accuracy: 0.937500    Val accuracy: 0.766044\n",
      "Epoch #40500    Loss: 0.031357    Train Accuracy: 1.000000    Val accuracy: 0.814429\n",
      "Epoch #40600    Loss: 0.143955    Train Accuracy: 0.968750    Val accuracy: 0.737650\n",
      "Epoch #40700    Loss: 0.233802    Train Accuracy: 0.906250    Val accuracy: 0.791395\n",
      "Epoch #40800    Loss: 0.121016    Train Accuracy: 0.937500    Val accuracy: 0.787484\n",
      "Epoch #40900    Loss: 0.132946    Train Accuracy: 0.906250    Val accuracy: 0.813414\n",
      "Epoch #41000    Loss: 0.121874    Train Accuracy: 0.937500    Val accuracy: 0.787049\n",
      "Epoch #41100    Loss: 0.292923    Train Accuracy: 0.937500    Val accuracy: 0.747066\n",
      "Epoch #41200    Loss: 0.084261    Train Accuracy: 1.000000    Val accuracy: 0.783862\n",
      "Epoch #41300    Loss: 0.051459    Train Accuracy: 1.000000    Val accuracy: 0.767492\n",
      "Epoch #41400    Loss: 0.086482    Train Accuracy: 0.968750    Val accuracy: 0.730552\n",
      "Epoch #41500    Loss: 0.095264    Train Accuracy: 0.968750    Val accuracy: 0.795306\n",
      "Epoch #41600    Loss: 0.062120    Train Accuracy: 1.000000    Val accuracy: 0.786904\n",
      "Epoch #41700    Loss: 0.171038    Train Accuracy: 0.968750    Val accuracy: 0.798638\n",
      "Epoch #41800    Loss: 0.215538    Train Accuracy: 0.937500    Val accuracy: 0.764885\n",
      "Epoch #41900    Loss: 0.147171    Train Accuracy: 0.937500    Val accuracy: 0.769955\n",
      "Epoch #42000    Loss: 0.135199    Train Accuracy: 0.968750    Val accuracy: 0.808924\n",
      "Epoch #42100    Loss: 0.087004    Train Accuracy: 0.968750    Val accuracy: 0.786615\n",
      "Epoch #42200    Loss: 0.126675    Train Accuracy: 0.968750    Val accuracy: 0.793858\n",
      "Epoch #42300    Loss: 0.111551    Train Accuracy: 0.937500    Val accuracy: 0.761843\n",
      "Epoch #42400    Loss: 0.048149    Train Accuracy: 0.968750    Val accuracy: 0.745908\n",
      "Epoch #42500    Loss: 0.131734    Train Accuracy: 0.937500    Val accuracy: 0.799073\n",
      "Epoch #42600    Loss: 0.100294    Train Accuracy: 0.937500    Val accuracy: 0.741996\n",
      "Epoch #42700    Loss: 0.050426    Train Accuracy: 0.968750    Val accuracy: 0.742286\n",
      "Epoch #42800    Loss: 0.081453    Train Accuracy: 0.968750    Val accuracy: 0.769231\n",
      "Epoch #42900    Loss: 0.161395    Train Accuracy: 0.937500    Val accuracy: 0.752716\n",
      "Epoch #43000    Loss: 0.038749    Train Accuracy: 1.000000    Val accuracy: 0.794147\n",
      "Epoch #43100    Loss: 0.086321    Train Accuracy: 0.937500    Val accuracy: 0.785311\n",
      "Epoch #43200    Loss: 0.058832    Train Accuracy: 1.000000    Val accuracy: 0.792554\n",
      "Epoch #43300    Loss: 0.107076    Train Accuracy: 0.906250    Val accuracy: 0.752571\n",
      "Epoch #43400    Loss: 0.190758    Train Accuracy: 0.906250    Val accuracy: 0.777343\n",
      "Epoch #43500    Loss: 0.159265    Train Accuracy: 0.937500    Val accuracy: 0.726206\n",
      "Epoch #43600    Loss: 0.083120    Train Accuracy: 0.968750    Val accuracy: 0.763436\n",
      "Epoch #43700    Loss: 0.098679    Train Accuracy: 0.968750    Val accuracy: 0.768796\n",
      "Epoch #43800    Loss: 0.229877    Train Accuracy: 0.906250    Val accuracy: 0.787773\n",
      "Epoch #43900    Loss: 0.045630    Train Accuracy: 1.000000    Val accuracy: 0.754599\n",
      "Epoch #44000    Loss: 0.079825    Train Accuracy: 0.968750    Val accuracy: 0.756483\n",
      "Epoch #44100    Loss: 0.108562    Train Accuracy: 0.937500    Val accuracy: 0.753730\n",
      "Epoch #44200    Loss: 0.080567    Train Accuracy: 0.968750    Val accuracy: 0.780965\n",
      "Epoch #44300    Loss: 0.194587    Train Accuracy: 0.937500    Val accuracy: 0.775460\n",
      "Epoch #44400    Loss: 0.142407    Train Accuracy: 0.968750    Val accuracy: 0.782703\n",
      "Epoch #44500    Loss: 0.256593    Train Accuracy: 0.875000    Val accuracy: 0.768217\n",
      "Epoch #44600    Loss: 0.109665    Train Accuracy: 0.968750    Val accuracy: 0.801970\n",
      "Epoch #44700    Loss: 0.204547    Train Accuracy: 0.906250    Val accuracy: 0.801680\n",
      "Epoch #44800    Loss: 0.050113    Train Accuracy: 0.968750    Val accuracy: 0.794147\n",
      "Epoch #44900    Loss: 0.120415    Train Accuracy: 0.968750    Val accuracy: 0.738519\n",
      "Epoch #45000    Loss: 0.178101    Train Accuracy: 0.937500    Val accuracy: 0.782413\n",
      "Epoch #45100    Loss: 0.119826    Train Accuracy: 0.937500    Val accuracy: 0.778937\n",
      "Epoch #45200    Loss: 0.082139    Train Accuracy: 0.968750    Val accuracy: 0.755903\n",
      "Epoch #45300    Loss: 0.166325    Train Accuracy: 0.906250    Val accuracy: 0.769520\n",
      "Epoch #45400    Loss: 0.081839    Train Accuracy: 0.968750    Val accuracy: 0.775895\n",
      "Epoch #45500    Loss: 0.138411    Train Accuracy: 0.937500    Val accuracy: 0.796176\n",
      "Epoch #45600    Loss: 0.201582    Train Accuracy: 0.937500    Val accuracy: 0.815587\n",
      "Epoch #45700    Loss: 0.146758    Train Accuracy: 0.968750    Val accuracy: 0.766623\n",
      "Epoch #45800    Loss: 0.155907    Train Accuracy: 0.937500    Val accuracy: 0.738230\n",
      "Epoch #45900    Loss: 0.146502    Train Accuracy: 0.937500    Val accuracy: 0.781689\n",
      "Epoch #46000    Loss: 0.033532    Train Accuracy: 1.000000    Val accuracy: 0.768072\n",
      "Epoch #46100    Loss: 0.058112    Train Accuracy: 0.968750    Val accuracy: 0.803709\n",
      "Epoch #46200    Loss: 0.089156    Train Accuracy: 0.937500    Val accuracy: 0.762857\n",
      "Epoch #46300    Loss: 0.109129    Train Accuracy: 0.968750    Val accuracy: 0.789802\n",
      "Epoch #46400    Loss: 0.146635    Train Accuracy: 0.968750    Val accuracy: 0.776329\n",
      "Epoch #46500    Loss: 0.154145    Train Accuracy: 0.968750    Val accuracy: 0.768362\n",
      "Epoch #46600    Loss: 0.205632    Train Accuracy: 0.906250    Val accuracy: 0.771838\n",
      "Epoch #46700    Loss: 0.196310    Train Accuracy: 0.937500    Val accuracy: 0.775605\n",
      "Epoch #46800    Loss: 0.034187    Train Accuracy: 1.000000    Val accuracy: 0.775460\n",
      "Epoch #46900    Loss: 0.105687    Train Accuracy: 0.968750    Val accuracy: 0.818050\n",
      "Epoch #47000    Loss: 0.084717    Train Accuracy: 0.968750    Val accuracy: 0.759235\n",
      "Epoch #47100    Loss: 0.142145    Train Accuracy: 0.937500    Val accuracy: 0.732145\n",
      "Epoch #47200    Loss: 0.363434    Train Accuracy: 0.875000    Val accuracy: 0.759959\n",
      "Epoch #47300    Loss: 0.083440    Train Accuracy: 0.937500    Val accuracy: 0.742431\n",
      "Epoch #47400    Loss: 0.037242    Train Accuracy: 1.000000    Val accuracy: 0.811676\n",
      "Epoch #47500    Loss: 0.111044    Train Accuracy: 0.937500    Val accuracy: 0.781544\n",
      "Epoch #47600    Loss: 0.089147    Train Accuracy: 0.968750    Val accuracy: 0.753151\n",
      "Epoch #47700    Loss: 0.077678    Train Accuracy: 0.968750    Val accuracy: 0.797769\n",
      "Epoch #47800    Loss: 0.120091    Train Accuracy: 0.937500    Val accuracy: 0.806606\n",
      "Epoch #47900    Loss: 0.043977    Train Accuracy: 1.000000    Val accuracy: 0.768796\n",
      "Epoch #48000    Loss: 0.060233    Train Accuracy: 0.968750    Val accuracy: 0.779371\n",
      "Epoch #48100    Loss: 0.170652    Train Accuracy: 0.968750    Val accuracy: 0.785021\n",
      "Epoch #48200    Loss: 0.074990    Train Accuracy: 0.968750    Val accuracy: 0.795886\n",
      "Epoch #48300    Loss: 0.088759    Train Accuracy: 0.968750    Val accuracy: 0.799797\n",
      "Epoch #48400    Loss: 0.116716    Train Accuracy: 0.968750    Val accuracy: 0.785890\n",
      "Epoch #48500    Loss: 0.401359    Train Accuracy: 0.843750    Val accuracy: 0.771549\n",
      "Epoch #48600    Loss: 0.112209    Train Accuracy: 0.968750    Val accuracy: 0.792554\n",
      "Epoch #48700    Loss: 0.079105    Train Accuracy: 0.968750    Val accuracy: 0.799363\n",
      "Epoch #48800    Loss: 0.072712    Train Accuracy: 0.968750    Val accuracy: 0.768072\n",
      "Epoch #48900    Loss: 0.106001    Train Accuracy: 0.968750    Val accuracy: 0.803853\n",
      "Epoch #49000    Loss: 0.146827    Train Accuracy: 0.937500    Val accuracy: 0.795741\n",
      "Epoch #49100    Loss: 0.188866    Train Accuracy: 0.875000    Val accuracy: 0.769665\n",
      "Epoch #49200    Loss: 0.084467    Train Accuracy: 0.968750    Val accuracy: 0.753875\n",
      "Epoch #49300    Loss: 0.065336    Train Accuracy: 0.968750    Val accuracy: 0.758366\n",
      "Epoch #49400    Loss: 0.138291    Train Accuracy: 0.968750    Val accuracy: 0.775025\n",
      "Epoch #49500    Loss: 0.138298    Train Accuracy: 0.937500    Val accuracy: 0.762857\n",
      "Epoch #49600    Loss: 0.133895    Train Accuracy: 0.937500    Val accuracy: 0.759525\n",
      "Epoch #49700    Loss: 0.074885    Train Accuracy: 0.968750    Val accuracy: 0.764161\n",
      "Epoch #49800    Loss: 0.168668    Train Accuracy: 0.968750    Val accuracy: 0.759815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #49900    Loss: 0.104046    Train Accuracy: 0.968750    Val accuracy: 0.746487\n",
      "Epoch #50000    Loss: 0.125168    Train Accuracy: 0.968750    Val accuracy: 0.737361\n",
      "Epoch #50100    Loss: 0.104873    Train Accuracy: 0.937500    Val accuracy: 0.764740\n",
      "Epoch #50200    Loss: 0.154962    Train Accuracy: 0.906250    Val accuracy: 0.790960\n",
      "Epoch #50300    Loss: 0.051051    Train Accuracy: 1.000000    Val accuracy: 0.817181\n",
      "Epoch #50400    Loss: 0.055973    Train Accuracy: 1.000000    Val accuracy: 0.801825\n",
      "Epoch #50500    Loss: 0.394010    Train Accuracy: 0.875000    Val accuracy: 0.786470\n",
      "Epoch #50600    Loss: 0.045241    Train Accuracy: 0.968750    Val accuracy: 0.805592\n",
      "Epoch #50700    Loss: 0.160803    Train Accuracy: 0.906250    Val accuracy: 0.776619\n",
      "Epoch #50800    Loss: 0.021586    Train Accuracy: 1.000000    Val accuracy: 0.800232\n",
      "Epoch #50900    Loss: 0.030877    Train Accuracy: 1.000000    Val accuracy: 0.736202\n",
      "Epoch #51000    Loss: 0.103863    Train Accuracy: 0.968750    Val accuracy: 0.771549\n",
      "Epoch #51100    Loss: 0.129809    Train Accuracy: 0.937500    Val accuracy: 0.789222\n",
      "Epoch #51200    Loss: 0.076734    Train Accuracy: 0.968750    Val accuracy: 0.759959\n",
      "Epoch #51300    Loss: 0.130189    Train Accuracy: 0.937500    Val accuracy: 0.780240\n",
      "Epoch #51400    Loss: 0.103275    Train Accuracy: 0.937500    Val accuracy: 0.792409\n",
      "Epoch #51500    Loss: 0.149629    Train Accuracy: 0.906250    Val accuracy: 0.760394\n",
      "Epoch #51600    Loss: 0.210353    Train Accuracy: 0.937500    Val accuracy: 0.754310\n",
      "Epoch #51700    Loss: 0.110931    Train Accuracy: 0.968750    Val accuracy: 0.772273\n",
      "Epoch #51800    Loss: 0.067122    Train Accuracy: 0.968750    Val accuracy: 0.770969\n",
      "Epoch #51900    Loss: 0.007143    Train Accuracy: 1.000000    Val accuracy: 0.781834\n",
      "Epoch #52000    Loss: 0.099974    Train Accuracy: 0.968750    Val accuracy: 0.790816\n",
      "Epoch #52100    Loss: 0.144666    Train Accuracy: 0.906250    Val accuracy: 0.759815\n",
      "Epoch #52200    Loss: 0.127331    Train Accuracy: 0.937500    Val accuracy: 0.770390\n",
      "Epoch #52300    Loss: 0.116515    Train Accuracy: 0.906250    Val accuracy: 0.735477\n",
      "Epoch #52400    Loss: 0.056892    Train Accuracy: 1.000000    Val accuracy: 0.787049\n",
      "Epoch #52500    Loss: 0.216122    Train Accuracy: 0.906250    Val accuracy: 0.756483\n",
      "Epoch #52600    Loss: 0.139125    Train Accuracy: 0.937500    Val accuracy: 0.750833\n",
      "Epoch #52700    Loss: 0.105489    Train Accuracy: 0.906250    Val accuracy: 0.781979\n",
      "Epoch #52800    Loss: 0.101629    Train Accuracy: 0.968750    Val accuracy: 0.773722\n",
      "Epoch #52900    Loss: 0.014029    Train Accuracy: 1.000000    Val accuracy: 0.798349\n",
      "Epoch #53000    Loss: 0.094518    Train Accuracy: 0.937500    Val accuracy: 0.807185\n",
      "Epoch #53100    Loss: 0.037314    Train Accuracy: 1.000000    Val accuracy: 0.763436\n",
      "Epoch #53200    Loss: 0.043059    Train Accuracy: 1.000000    Val accuracy: 0.758801\n",
      "Epoch #53300    Loss: 0.079054    Train Accuracy: 0.968750    Val accuracy: 0.787629\n",
      "Epoch #53400    Loss: 0.093127    Train Accuracy: 0.968750    Val accuracy: 0.770390\n",
      "Epoch #53500    Loss: 0.126677    Train Accuracy: 0.937500    Val accuracy: 0.774880\n",
      "Epoch #53600    Loss: 0.047505    Train Accuracy: 1.000000    Val accuracy: 0.775170\n",
      "Epoch #53700    Loss: 0.188379    Train Accuracy: 0.937500    Val accuracy: 0.800811\n",
      "Epoch #53800    Loss: 0.704750    Train Accuracy: 0.781250    Val accuracy: 0.799797\n",
      "Epoch #53900    Loss: 0.365813    Train Accuracy: 0.875000    Val accuracy: 0.785890\n",
      "Epoch #54000    Loss: 0.194628    Train Accuracy: 0.937500    Val accuracy: 0.734753\n",
      "Epoch #54100    Loss: 0.088695    Train Accuracy: 1.000000    Val accuracy: 0.736636\n",
      "Epoch #54200    Loss: 0.051815    Train Accuracy: 0.968750    Val accuracy: 0.758366\n",
      "Epoch #54300    Loss: 0.154333    Train Accuracy: 0.906250    Val accuracy: 0.795886\n",
      "Epoch #54400    Loss: 0.089117    Train Accuracy: 0.968750    Val accuracy: 0.760973\n",
      "Epoch #54500    Loss: 0.155984    Train Accuracy: 0.875000    Val accuracy: 0.776474\n",
      "Epoch #54600    Loss: 0.389411    Train Accuracy: 0.906250    Val accuracy: 0.808344\n",
      "Epoch #54700    Loss: 0.277348    Train Accuracy: 0.875000    Val accuracy: 0.791395\n",
      "Epoch #54800    Loss: 0.138902    Train Accuracy: 0.906250    Val accuracy: 0.763146\n",
      "Epoch #54900    Loss: 0.060266    Train Accuracy: 1.000000    Val accuracy: 0.757207\n",
      "Epoch #55000    Loss: 0.083752    Train Accuracy: 0.968750    Val accuracy: 0.777053\n",
      "Epoch #55100    Loss: 0.044373    Train Accuracy: 1.000000    Val accuracy: 0.751992\n",
      "Epoch #55200    Loss: 0.116514    Train Accuracy: 0.937500    Val accuracy: 0.771259\n",
      "Epoch #55300    Loss: 0.068559    Train Accuracy: 1.000000    Val accuracy: 0.758945\n",
      "Epoch #55400    Loss: 0.058850    Train Accuracy: 0.968750    Val accuracy: 0.817181\n",
      "Epoch #55500    Loss: 0.156649    Train Accuracy: 0.937500    Val accuracy: 0.801391\n",
      "Epoch #55600    Loss: 0.025708    Train Accuracy: 1.000000    Val accuracy: 0.784007\n",
      "Epoch #55700    Loss: 0.153989    Train Accuracy: 0.937500    Val accuracy: 0.733015\n",
      "Epoch #55800    Loss: 0.067887    Train Accuracy: 0.968750    Val accuracy: 0.784442\n",
      "Epoch #55900    Loss: 0.047013    Train Accuracy: 1.000000    Val accuracy: 0.777343\n",
      "Epoch #56000    Loss: 0.132173    Train Accuracy: 0.968750    Val accuracy: 0.760973\n",
      "Epoch #56100    Loss: 0.095798    Train Accuracy: 0.968750    Val accuracy: 0.780240\n",
      "Epoch #56200    Loss: 0.254663    Train Accuracy: 0.906250    Val accuracy: 0.756628\n",
      "Epoch #56300    Loss: 0.176714    Train Accuracy: 0.906250    Val accuracy: 0.780675\n",
      "Epoch #56400    Loss: 0.107109    Train Accuracy: 0.968750    Val accuracy: 0.816167\n",
      "Epoch #56500    Loss: 0.139089    Train Accuracy: 0.968750    Val accuracy: 0.770824\n",
      "Epoch #56600    Loss: 0.032396    Train Accuracy: 1.000000    Val accuracy: 0.765464\n",
      "Epoch #56700    Loss: 0.107078    Train Accuracy: 0.968750    Val accuracy: 0.750109\n",
      "Epoch #56800    Loss: 0.076651    Train Accuracy: 0.968750    Val accuracy: 0.775170\n",
      "Epoch #56900    Loss: 0.172646    Train Accuracy: 0.937500    Val accuracy: 0.736202\n",
      "Epoch #57000    Loss: 0.290001    Train Accuracy: 0.937500    Val accuracy: 0.785021\n",
      "Epoch #57100    Loss: 0.046783    Train Accuracy: 1.000000    Val accuracy: 0.797045\n",
      "Epoch #57200    Loss: 0.093695    Train Accuracy: 0.968750    Val accuracy: 0.766913\n",
      "Epoch #57300    Loss: 0.261261    Train Accuracy: 0.875000    Val accuracy: 0.757642\n",
      "Epoch #57400    Loss: 0.142210    Train Accuracy: 0.875000    Val accuracy: 0.775025\n",
      "Epoch #57500    Loss: 0.063875    Train Accuracy: 0.968750    Val accuracy: 0.751412\n",
      "Epoch #57600    Loss: 0.118168    Train Accuracy: 0.937500    Val accuracy: 0.756338\n",
      "Epoch #57700    Loss: 0.071027    Train Accuracy: 0.968750    Val accuracy: 0.777053\n",
      "Epoch #57800    Loss: 0.099369    Train Accuracy: 0.968750    Val accuracy: 0.748660\n",
      "Epoch #57900    Loss: 0.113176    Train Accuracy: 0.906250    Val accuracy: 0.767782\n",
      "Epoch #58000    Loss: 0.044470    Train Accuracy: 0.968750    Val accuracy: 0.755324\n",
      "Epoch #58100    Loss: 0.157243    Train Accuracy: 0.937500    Val accuracy: 0.768072\n",
      "Epoch #58200    Loss: 0.066769    Train Accuracy: 0.968750    Val accuracy: 0.804578\n",
      "Epoch #58300    Loss: 0.159820    Train Accuracy: 0.937500    Val accuracy: 0.777488\n",
      "Epoch #58400    Loss: 0.151656    Train Accuracy: 0.937500    Val accuracy: 0.752137\n",
      "Epoch #58500    Loss: 0.274999    Train Accuracy: 0.937500    Val accuracy: 0.747936\n",
      "Epoch #58600    Loss: 0.072793    Train Accuracy: 1.000000    Val accuracy: 0.780096\n",
      "Epoch #58700    Loss: 0.082822    Train Accuracy: 0.968750    Val accuracy: 0.758221\n",
      "Epoch #58800    Loss: 0.122110    Train Accuracy: 0.968750    Val accuracy: 0.770390\n",
      "Epoch #58900    Loss: 0.107102    Train Accuracy: 0.937500    Val accuracy: 0.769231\n",
      "Epoch #59000    Loss: 0.140665    Train Accuracy: 0.875000    Val accuracy: 0.749239\n",
      "Epoch #59100    Loss: 0.033181    Train Accuracy: 1.000000    Val accuracy: 0.785311\n",
      "Epoch #59200    Loss: 0.031805    Train Accuracy: 1.000000    Val accuracy: 0.753006\n",
      "Epoch #59300    Loss: 0.023833    Train Accuracy: 1.000000    Val accuracy: 0.728958\n",
      "Epoch #59400    Loss: 0.178472    Train Accuracy: 0.906250    Val accuracy: 0.780965\n",
      "Epoch #59500    Loss: 0.167676    Train Accuracy: 0.875000    Val accuracy: 0.765319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #59600    Loss: 0.116370    Train Accuracy: 0.968750    Val accuracy: 0.801391\n",
      "Epoch #59700    Loss: 0.149622    Train Accuracy: 0.937500    Val accuracy: 0.758945\n",
      "Epoch #59800    Loss: 0.205578    Train Accuracy: 0.875000    Val accuracy: 0.756917\n",
      "Epoch #59900    Loss: 0.125928    Train Accuracy: 0.937500    Val accuracy: 0.756048\n",
      "Epoch #60000    Loss: 0.074331    Train Accuracy: 0.968750    Val accuracy: 0.746052\n",
      "Epoch #60100    Loss: 0.069510    Train Accuracy: 1.000000    Val accuracy: 0.779082\n",
      "Epoch #60200    Loss: 0.156766    Train Accuracy: 0.968750    Val accuracy: 0.746342\n",
      "Epoch #60300    Loss: 0.040933    Train Accuracy: 1.000000    Val accuracy: 0.753006\n",
      "Epoch #60400    Loss: 0.053945    Train Accuracy: 0.968750    Val accuracy: 0.772563\n",
      "Epoch #60500    Loss: 0.065610    Train Accuracy: 1.000000    Val accuracy: 0.737650\n",
      "Epoch #60600    Loss: 0.102082    Train Accuracy: 1.000000    Val accuracy: 0.783427\n",
      "Epoch #60700    Loss: 0.118715    Train Accuracy: 0.937500    Val accuracy: 0.794727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f8a8ff6ebc48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e3a3206f5f42>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mtotal_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1930\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m       outputs = training_eager.train_on_batch(\n\u001b[0;32m-> 1932\u001b[0;31m           self, x, y, sample_weights=sample_weights)\n\u001b[0m\u001b[1;32m   1933\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   outs, loss, loss_metrics, masks = _process_single_batch(\n\u001b[0;32m--> 556\u001b[0;31m       model, inputs, targets, sample_weights=sample_weights, training=True)\n\u001b[0m\u001b[1;32m    557\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, sample_weights, training)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[0;32m--> 523\u001b[0;31m                                             model._collected_trainable_weights))\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    608\u001b[0m           \u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"update_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m           \u001b[0mupdate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mapply_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mupdate_op\u001b[0;34m(self, optimizer, g)\u001b[0m\n\u001b[1;32m    166\u001b[0m           g.values, self._v, g.indices)\n\u001b[1;32m    167\u001b[0m     \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mconstraint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0mCan\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mconstraint\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mpassed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \"\"\"\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset_from_tfrecord(TRAIN_OUTPUT_DIR_PATH, TRAIN_BATCH_SIZE)\n",
    "val_dataset = create_dataset_from_tfrecord(VAL_OUTPUT_DIR_PATH, VAL_BATCH_SIZE)\n",
    "\n",
    "if False : \n",
    "    model = keras.models.load_model('/work/nas/emotion/03_CheckPoint/smile_keras_test_190411/ckpt/emotion_mobilenet_v1_0.77.h5')\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001), \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "else :\n",
    "    emonet = MobileNetV1(0.001)\n",
    "    model = emonet.create_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model = train_model(model, train_dataset, val_dataset, BATCH_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for val_images, val_labels in val_dataset :\n",
    "    print(val_labels)\n",
    "    prediction = model.predict(val_images)\n",
    "    prediction = tf.argmax(prediction, 1)\n",
    "    print(prediction)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
