{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Record Writing\n",
    "- - - \n",
    "Followed codes are examples of writing TF Records with multi-threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setting\n",
    "- - - \n",
    "* Below block sets paths and parameters. See the details at the end of parameters.\n",
    "* __You have to set bool parameters properly below__\n",
    "* Multi directory data loading is not supported so far. (190319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=6\n",
    "\n",
    "#################################################\n",
    "# You have to set this bool parameters properly #\n",
    "#################################################\n",
    "USE_LABEL_FILE = True\n",
    "USE_GRAYSCALE = True\n",
    "USE_RESIZING = False\n",
    "USE_DATA_SLICING = False\n",
    "USE_TRAIN_AUG = False\n",
    "USE_VAL_AUG = False\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "\n",
    "TARGET_TRAIN = \"train\"\n",
    "TARGET_VAL = \"val\"\n",
    "\n",
    "IMAGE_THRESHOLD = 700 # Threshold of width and height\n",
    "\n",
    "MIN_IMAGE_DATASET = 3000 # Number of minimum count of image datasets\n",
    "MAX_IMAGE_DATASET = 0 # Number of maximum count of image datasets\n",
    "\n",
    "VAL_DATA_PROPORTION = 0.2 # Proportion of validation data out of 100\n",
    "\n",
    "TRAIN_SHARDS = 8 # Number of shards in training TFRecord files. Should be multiple of threads\n",
    "VAL_SHARDS = 4 # Number of shards in validation TFRecord files. Should be multiple of threads\n",
    "NUM_OF_THREADS = 4 # Number of threads to preprocess the images\n",
    "\n",
    "IMAGE_DIR_PATH = '/work/nas/emotion/01_Data/emotion_data' # Image directory used for one image source\n",
    "# TRAIN_DIR_PATH = '/work/nas/emotion/01_Data/emotion_data' # Train image directory used for separated image source\n",
    "# VAL_DIR_PATH = '/work/nas/emotion/01_Data/emotion_data' # Validation image directory used for separated image source\n",
    "TRAIN_DIR_PATH = '/work/data/emotion/FER2013_Emotion/Training'\n",
    "VAL_DIR_PATH = '/work/data/emotion/FER2013_Emotion/PrivateTest'\n",
    "\n",
    "# TRAIN_DIR_PATH2 = '/home/youngtak.na/imagenet/ILSVRC/Data/CLS-LOC/train' # Use if there is one more folder\n",
    "# VAL_DIR_PATH2 = '/home/youngtak.na/imagenet/ILSVRC/Data/CLS-LOC/val' # Use if there is one more folder\n",
    "\n",
    "# OUTPUT_DIR_PATH = '/work/nas/emotion/02_TFRecords/190315_min_3000'\n",
    "OUTPUT_DIR_PATH = './tfrecords/FER2013'\n",
    "TRAIN_OUTPUT_DIR_PATH = OUTPUT_DIR_PATH + \"/train\"\n",
    "VAL_OUTPUT_DIR_PATH = OUTPUT_DIR_PATH + \"/val\"\n",
    "\n",
    "# LABEL_PATH = '/work/nas/emotion/01_Data/emotion_data/emotion_label.txt' # Could be file or dir that has folders named as labels\n",
    "LABEL_PATH = '/work/data/emotion/FER2013_Emotion/label.txt' # Could be file or dir that has folders named as labels\n",
    "\n",
    "LOG_FILE_PATH = OUTPUT_DIR_PATH + '/log.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TF Record Utils\n",
    "- - - \n",
    "* This block is about TF Record utils to convert to TF Record example.\n",
    "* __You have to edit convert_to_example function for fit your model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to_example(filename, image_buffer, label, height, width):\n",
    "    colorspace = b'RGB'\n",
    "    channels = 3\n",
    "    image_format = b'JPEG'\n",
    "    \n",
    "    if USE_GRAYSCALE :\n",
    "        colorspace = b'L'\n",
    "        channels = 1    \n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "          'image/height': int64_feature(height),\n",
    "          'image/width': int64_feature(width),\n",
    "          'image/colorspace': bytes_feature(colorspace),\n",
    "          'image/channels': int64_feature(channels),\n",
    "          'image/class/label': int64_feature(label),\n",
    "          'image/format': bytes_feature(image_format),\n",
    "          'image/filename': bytes_feature(os.path.basename(filename).encode('UTF-8')),\n",
    "          'image/encoded': bytes_feature(image_buffer)}))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Processing Utils\n",
    "- - - \n",
    "* This block is about image processing utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_to_jpeg(image_data, channels):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=channels) # 3\n",
    "    return tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "def cmyk_to_rgb(image_data, channels):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=channels) # 0\n",
    "    return tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "def decode_jpeg(image_data, channels):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=channels) # 3\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == channels\n",
    "    return image\n",
    "\n",
    "def check_valid_image(img_path, grayscale=False) :\n",
    "    try :\n",
    "        img = Image.open(img_path)\n",
    "        img.verify()\n",
    "        if not grayscale and img.mode != 'RGB' and img.mode != 'CMYK':\n",
    "            print(img_path, ' is excluded [', img.mode, ']')\n",
    "            return False\n",
    "    except Exception as ex :\n",
    "        print_and_write_log(\"[Exception] : %s\" % ex) \n",
    "        return False\n",
    "       \n",
    "    return True\n",
    "\n",
    "def resize_image_threshold(image, threshold):\n",
    "    resized_image = image\n",
    "    width, height = image.size\n",
    "\n",
    "    while ((width > threshold) | (height > threshold)):\n",
    "        height = int(height / 2)\n",
    "        width = int(width / 2)\n",
    "        resized_image = image.resize((width, height))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "def convert_image_grayscale(image) :\n",
    "    gray_image = image\n",
    "    if image.mode != 'L' :\n",
    "        gray_image = image.convert('L')\n",
    "\n",
    "    return gray_image\n",
    "\n",
    "def get_image_bytes(image) :\n",
    "    image_bytes = io.BytesIO()\n",
    "    image.save(image_bytes, format='JPEG')\n",
    "    return image_bytes.getvalue()\n",
    "    \n",
    "def process_image(file_name):\n",
    "    with Image.open(file_name) as image :\n",
    "        if USE_RESIZING :\n",
    "            image = resize_image_threshold(image, IMAGE_THRESHOLD)\n",
    "        if USE_GRAYSCALE :\n",
    "            image = convert_image_grayscale(image)\n",
    "\n",
    "        width, height = image.size\n",
    "        image_data = get_image_bytes(image)\n",
    "        \n",
    "#     image_data = tf.gfile.GFile(filename, 'rb').read()\n",
    "\n",
    "    # Clean the dirty data.\n",
    "    #   if _is_png(filename):\n",
    "    #     # 1 image is a PNG.\n",
    "    #     print('Converting PNG to JPEG for %s' % filename)\n",
    "    #     image_data = coder.png_to_jpeg(image_data)\n",
    "    #   elif _is_cmyk(filename):\n",
    "    #     print('Converting CMYK to RGB for %s' % filename)\n",
    "    #     image_data = coder.cmyk_to_rgb(image_data)\n",
    "#     if USE_GRAYSCALE :\n",
    "#         image = decode_jpeg(image_data, 1)\n",
    "\n",
    "#     height = image.shape[0]\n",
    "#     width = image.shape[1]\n",
    "\n",
    "    return image_data, height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Utils\n",
    "- - - \n",
    "* This block is about basic utils for making TF Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_write_log(log, print_log=True) :\n",
    "    if print_log is True :\n",
    "        print(\"{} : {}\".format(datetime.now(), log))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    if not os.path.exists(OUTPUT_DIR_PATH) :\n",
    "        make_directory(OUTPUT_DIR_PATH)\n",
    "            \n",
    "    with open(LOG_FILE_PATH, \"a\") as f_log :\n",
    "        f_log.write(\"{} : {}\\n\".format(datetime.now(), log))\n",
    "        \n",
    "def make_directory(dir_path) :\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"Directory is created in \", dir_path)\n",
    "\n",
    "def load_labels(label_path, use_file) :    \n",
    "    labels = []\n",
    "    if use_file :\n",
    "        with open(label_path, 'r') as f :\n",
    "            for line in f.readlines() :\n",
    "                labels.append(line.strip())\n",
    "#             labels.sort()\n",
    "    else :\n",
    "        image_dirs = os.listdir(label_path)\n",
    "        image_dirs.sort()\n",
    "        labels = image_dirs\n",
    "    \n",
    "    print_and_write_log(\"Label count : %d\" % len(labels))\n",
    "    return labels\n",
    "\n",
    "def get_shards_and_batch(target) :\n",
    "    assert target == TARGET_TRAIN or target == TARGET_VAL, \"[Error] Target name is not matching\"\n",
    "\n",
    "    if target == TARGET_TRAIN :\n",
    "        num_of_shards = TRAIN_SHARDS    \n",
    "    elif target == TARGET_VAL :\n",
    "        num_of_shards = VAL_SHARDS\n",
    "    \n",
    "    assert not num_of_shards % NUM_OF_THREADS, \"[Error] Shards should be multiple of threads\"\n",
    "    num_shards_per_batch = int(num_of_shards / NUM_OF_THREADS)\n",
    "    \n",
    "    return num_shards_per_batch, num_of_shards\n",
    "\n",
    "def get_augmented_index(index_len, aug_len) :\n",
    "    np.random.seed(int(datetime.timestamp(datetime.now())))\n",
    "    augmented_index = []\n",
    "    while len(augmented_index) < aug_len :\n",
    "        random_index = np.random.choice(range(0, index_len), index_len, replace=False)\n",
    "        augmented_index.extend(random_index)\n",
    "    \n",
    "    return augmented_index[:aug_len]\n",
    "\n",
    "def get_shuffled_index(index_len) :\n",
    "    shuffled_index = np.arange(index_len)\n",
    "    random.seed(int(datetime.timestamp(datetime.now())))\n",
    "    random.shuffle(shuffled_index)\n",
    "    return shuffled_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Dataset and Writing TF Records\n",
    "- - - \n",
    "* This block is about making dataset and TF Records.\n",
    "> * Make_dataset\n",
    ">> * Read datas from data directory with labels.\n",
    ">> * You can get augmented datas with set __data_aug__ flag True.\n",
    ">> * And it supports slicing dataset to divide training set and validation set.\n",
    "> * Make_tfrecords\n",
    ">> * Make TF Records by multi-threading.\n",
    ">> * You have to set target with __\"train\" or \"val\"__ to get shards and batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_dir_path, original_labels, data_aug=False, slice_range=[0,1]):\n",
    "    labels = []\n",
    "    file_paths = []\n",
    "    \n",
    "    for label_index in range(len(original_labels)):\n",
    "        matching_file_paths = []\n",
    "        img_file_path = '%s/%s/*.jpg' % (data_dir_path, original_labels[label_index])\n",
    "        \n",
    "        cand_file_paths = tf.gfile.Glob(img_file_path)\n",
    "        for img_path in cand_file_paths :\n",
    "            if check_valid_image(img_path, grayscale=USE_GRAYSCALE) :\n",
    "                matching_file_paths.append(img_path)\n",
    "        \n",
    "        matching_file_paths.sort()\n",
    "        print_and_write_log('Matching files : %d' % len(matching_file_paths))\n",
    "            \n",
    "        if slice_range[0] != 0 or slice_range[1] != 1 :\n",
    "            start_index = int(len(matching_file_paths) * slice_range[0])\n",
    "            end_index = int(len(matching_file_paths) * slice_range[1])\n",
    "            matching_file_paths = matching_file_paths[start_index : end_index]\n",
    "            print_and_write_log('Slice matching files %d : %d to %d ' % (end_index - start_index, start_index, end_index))\n",
    "       \n",
    "        if data_aug == True and len(matching_file_paths) > MAX_IMAGE_DATASET :\n",
    "            matching_file_paths = matching_file_paths[:MAX_IMAGE_DATASET]\n",
    "        \n",
    "        if data_aug == True and len(matching_file_paths) < MIN_IMAGE_DATASET :\n",
    "            aug_len = MIN_IMAGE_DATASET - len(matching_file_paths)\n",
    "            \n",
    "            augmented_index = get_augmented_index(len(matching_file_paths), aug_len)\n",
    "            augmented_file_paths = [matching_file_paths[i] for i in augmented_index]\n",
    "            matching_file_paths.extend(augmented_file_paths)\n",
    "            \n",
    "            print_and_write_log(\"Add augmented files : %d\" % aug_len)\n",
    "\n",
    "        file_paths.extend(matching_file_paths)\n",
    "        labels.extend([label_index] * len(matching_file_paths))\n",
    "\n",
    "        print_and_write_log('Finished finding %s files %s in %d of %d classes.' % (len(matching_file_paths), \n",
    "                original_labels[label_index], label_index + 1, len(original_labels)))\n",
    "        \n",
    "    shuffled_index = get_shuffled_index(len(file_paths))\n",
    "\n",
    "    file_paths = [file_paths[i] for i in shuffled_index]\n",
    "    labels = [labels[i] for i in shuffled_index]\n",
    "    \n",
    "    print_and_write_log('Found %d JPEG files across %d labels inside %s.' %\n",
    "        (len(file_paths), len(original_labels), data_dir_path))\n",
    "    \n",
    "    return file_paths, labels\n",
    "\n",
    "def make_tfrecords_by_thread(file_paths, labels, target) :\n",
    "    assert len(file_paths) == len(labels), \"[Error] Files and labels length should be same\"\n",
    "    \n",
    "    ranges = []\n",
    "    threads = []\n",
    "    coordinator = tf.train.Coordinator()\n",
    "\n",
    "    spacing = np.linspace(0, len(file_paths), NUM_OF_THREADS + 1).astype(np.int)\n",
    "    for i in xrange(len(spacing) - 1):\n",
    "        ranges.append([spacing[i], spacing[i+1]])\n",
    "    print_and_write_log('Launching {} threads for spacings: {}'.format(NUM_OF_THREADS, ranges))\n",
    "\n",
    "    make_directory(os.path.join(OUTPUT_DIR_PATH, target))\n",
    "    \n",
    "    for thread_index in xrange(len(ranges)):\n",
    "        args = (thread_index, ranges, file_paths, labels, target)\n",
    "        t = threading.Thread(target=make_tfrecords_batch, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    \n",
    "    coordinator.join(threads)\n",
    "    print_and_write_log('Finished writing all %d images in data set.' % (len(file_paths)))\n",
    "\n",
    "def make_tfrecords_batch(thread_index, ranges, file_paths, labels, target):\n",
    "    total_counter = 0\n",
    "    num_shards_per_batch, num_of_shards = get_shards_and_batch(target)\n",
    "    num_files_per_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "    shard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "    \n",
    "    for index in xrange(num_shards_per_batch):\n",
    "        shard_counter = 0\n",
    "        shard_index = thread_index * num_shards_per_batch + index\n",
    "              \n",
    "        output_filename = '%s-%.3d-of-%.3d.tfrecord' % (target, shard_index + 1, num_of_shards)\n",
    "        output_file = os.path.join(OUTPUT_DIR_PATH, target + \"/\" + output_filename)\n",
    "        \n",
    "        with tf.python_io.TFRecordWriter(output_file) as writer :\n",
    "            for i in range(shard_ranges[index], shard_ranges[index + 1]) :\n",
    "                try :\n",
    "                    image_buffer, height, width = process_image(file_paths[i])\n",
    "\n",
    "                    example = convert_to_example(file_paths[i], image_buffer, labels[i], height, width)\n",
    "                    writer.write(example.SerializeToString())\n",
    "\n",
    "                    shard_counter += 1\n",
    "                    total_counter += 1\n",
    "\n",
    "                    if not total_counter % 1000:\n",
    "                        print_and_write_log('[thread %d]: Processed %d of %d images in thread batch.' %\n",
    "                              (thread_index, total_counter, num_files_per_thread))\n",
    "                except OSError as e :\n",
    "                    print_and_write_log(str(e))\n",
    "\n",
    "        print_and_write_log('[thread %d]: Wrote %d images to %s' %\n",
    "              (thread_index, shard_counter, output_file))\n",
    "    \n",
    "    print_and_write_log('[thread %d]: Wrote %d images to %d shards.' %\n",
    "        (thread_index, total_counter, num_shards_per_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 16:04:18.257435 : Label count : 7\n",
      "2019-03-19 16:04:18.636855 : Matching files : 3995\n",
      "2019-03-19 16:04:18.638725 : Finished finding 3995 files angry in 1 of 7 classes.\n",
      "2019-03-19 16:04:18.703541 : Matching files : 436\n",
      "2019-03-19 16:04:18.704915 : Finished finding 436 files disgust in 2 of 7 classes.\n",
      "2019-03-19 16:04:19.102089 : Matching files : 4097\n",
      "2019-03-19 16:04:19.104005 : Finished finding 4097 files fear in 3 of 7 classes.\n",
      "2019-03-19 16:04:20.023710 : Matching files : 7215\n",
      "2019-03-19 16:04:20.026326 : Finished finding 7215 files happy in 4 of 7 classes.\n",
      "2019-03-19 16:04:20.658915 : Matching files : 4965\n",
      "2019-03-19 16:04:20.660374 : Finished finding 4965 files neutral in 5 of 7 classes.\n",
      "2019-03-19 16:04:21.358889 : Matching files : 4830\n",
      "2019-03-19 16:04:21.361258 : Finished finding 4830 files sad in 6 of 7 classes.\n",
      "2019-03-19 16:04:21.674659 : Matching files : 3171\n",
      "2019-03-19 16:04:21.676562 : Finished finding 3171 files surprise in 7 of 7 classes.\n",
      "2019-03-19 16:04:21.726077 : Found 28709 JPEG files across 7 labels inside /work/data/emotion/FER2013_Emotion/Training.\n",
      "2019-03-19 16:04:21.818979 : Matching files : 491\n",
      "2019-03-19 16:04:21.820585 : Finished finding 491 files angry in 1 of 7 classes.\n",
      "2019-03-19 16:04:21.834170 : Matching files : 55\n",
      "2019-03-19 16:04:21.835680 : Finished finding 55 files disgust in 2 of 7 classes.\n",
      "2019-03-19 16:04:21.891036 : Matching files : 528\n",
      "2019-03-19 16:04:21.892144 : Finished finding 528 files fear in 3 of 7 classes.\n",
      "2019-03-19 16:04:21.962608 : Matching files : 879\n",
      "2019-03-19 16:04:21.964801 : Finished finding 879 files happy in 4 of 7 classes.\n",
      "2019-03-19 16:04:22.026132 : Matching files : 626\n",
      "2019-03-19 16:04:22.028594 : Finished finding 626 files neutral in 5 of 7 classes.\n",
      "2019-03-19 16:04:22.079434 : Matching files : 594\n",
      "2019-03-19 16:04:22.081009 : Finished finding 594 files sad in 6 of 7 classes.\n",
      "2019-03-19 16:04:22.119407 : Matching files : 416\n",
      "2019-03-19 16:04:22.120698 : Finished finding 416 files surprise in 7 of 7 classes.\n",
      "2019-03-19 16:04:22.129374 : Found 3589 JPEG files across 7 labels inside /work/data/emotion/FER2013_Emotion/PrivateTest.\n",
      "2019-03-19 16:04:22.132319 : Launching 4 threads for spacings: [[0, 7177], [7177, 14354], [14354, 21531], [21531, 28709]]\n",
      "2019-03-19 16:04:25.753543 : [thread 1]: Processed 1000 of 7177 images in thread batch.2019-03-19 16:04:25.754628 : [thread 3]: Processed 1000 of 7178 images in thread batch.\n",
      "\n",
      "2019-03-19 16:04:25.933907 : [thread 0]: Processed 1000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:25.938159 : [thread 2]: Processed 1000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:29.624888 : [thread 3]: Processed 2000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:29.664742 : [thread 1]: Processed 2000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:29.846152 : [thread 2]: Processed 2000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:29.911471 : [thread 0]: Processed 2000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:33.374956 : [thread 3]: Processed 3000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:33.436261 : [thread 1]: Processed 3000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:33.790766 : [thread 0]: Processed 3000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:33.818262 : [thread 2]: Processed 3000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:35.441228 : [thread 3]: Wrote 3589 images to ./tfrecords/FER2013/train/train-007-of-008.tfrecord\n",
      "2019-03-19 16:04:35.601463 : [thread 1]: Wrote 3588 images to ./tfrecords/FER2013/train/train-003-of-008.tfrecord\n",
      "2019-03-19 16:04:35.885316 : [thread 0]: Wrote 3588 images to ./tfrecords/FER2013/train/train-001-of-008.tfrecord\n",
      "2019-03-19 16:04:36.015115 : [thread 2]: Wrote 3588 images to ./tfrecords/FER2013/train/train-005-of-008.tfrecord\n",
      "2019-03-19 16:04:36.997293 : [thread 3]: Processed 4000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:37.181759 : [thread 1]: Processed 4000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:37.506068 : [thread 0]: Processed 4000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:37.604588 : [thread 2]: Processed 4000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:40.799207 : [thread 3]: Processed 5000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:40.979301 : [thread 1]: Processed 5000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:41.351264 : [thread 0]: Processed 5000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:41.423952 : [thread 2]: Processed 5000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:44.564359 : [thread 3]: Processed 6000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:44.877064 : [thread 1]: Processed 6000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:45.075239 : [thread 0]: Processed 6000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:45.177599 : [thread 2]: Processed 6000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:48.435356 : [thread 3]: Processed 7000 of 7178 images in thread batch.\n",
      "2019-03-19 16:04:48.742096 : [thread 1]: Processed 7000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:48.886266 : [thread 0]: Processed 7000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:48.942628 : [thread 2]: Processed 7000 of 7177 images in thread batch.\n",
      "2019-03-19 16:04:49.170187 : [thread 3]: Wrote 3589 images to ./tfrecords/FER2013/train/train-008-of-008.tfrecord\n",
      "2019-03-19 16:04:49.174723 : [thread 3]: Wrote 7178 images to 2 shards.\n",
      "2019-03-19 16:04:49.364653 : [thread 1]: Wrote 3589 images to ./tfrecords/FER2013/train/train-004-of-008.tfrecord\n",
      "2019-03-19 16:04:49.370434 : [thread 1]: Wrote 7177 images to 2 shards.\n",
      "2019-03-19 16:04:49.417955 : [thread 0]: Wrote 3589 images to ./tfrecords/FER2013/train/train-002-of-008.tfrecord\n",
      "2019-03-19 16:04:49.420468 : [thread 0]: Wrote 7177 images to 2 shards.\n",
      "2019-03-19 16:04:49.439386 : [thread 2]: Wrote 3589 images to ./tfrecords/FER2013/train/train-006-of-008.tfrecord\n",
      "2019-03-19 16:04:49.440744 : [thread 2]: Wrote 7177 images to 2 shards.\n",
      "2019-03-19 16:04:50.159821 : Finished writing all 28709 images in data set.\n",
      "2019-03-19 16:04:50.163063 : Launching 4 threads for spacings: [[0, 897], [897, 1794], [1794, 2691], [2691, 3589]]\n",
      "Directory is created in  ./tfrecords/FER2013/val\n",
      "2019-03-19 16:04:53.470967 : [thread 0]: Wrote 897 images to ./tfrecords/FER2013/val/val-001-of-004.tfrecord\n",
      "2019-03-19 16:04:53.479666 : [thread 0]: Wrote 897 images to 1 shards.\n",
      "2019-03-19 16:04:53.527740 : [thread 1]: Wrote 897 images to ./tfrecords/FER2013/val/val-002-of-004.tfrecord\n",
      "2019-03-19 16:04:53.531644 : [thread 1]: Wrote 897 images to 1 shards.\n",
      "2019-03-19 16:04:53.538267 : [thread 2]: Wrote 897 images to ./tfrecords/FER2013/val/val-003-of-004.tfrecord\n",
      "2019-03-19 16:04:53.541374 : [thread 2]: Wrote 897 images to 1 shards.\n",
      "2019-03-19 16:04:53.555062 : [thread 3]: Wrote 898 images to ./tfrecords/FER2013/val/val-004-of-004.tfrecord\n",
      "2019-03-19 16:04:53.556533 : [thread 3]: Wrote 898 images to 1 shards.\n",
      "2019-03-19 16:04:54.170714 : Finished writing all 3589 images in data set.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjune.jeong/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3299: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "    if os.path.exists(LOG_FILE_PATH) :\n",
    "        os.remove(LOG_FILE_PATH)\n",
    "    \n",
    "    original_labels = load_labels(LABEL_PATH, USE_LABEL_FILE)\n",
    "    \n",
    "    if USE_DATA_SLICING :\n",
    "        assert VAL_DATA_PROPORTION > 0 and VAL_DATA_PROPORTION < 1, \"[Error] Proportion should be between 0 and 1\"\n",
    "        train_file_paths, train_labels = make_dataset(IMAGE_DIR_PATH, original_labels, USE_TRAIN_AUG, [0, 1-VAL_DATA_PROPORTION])\n",
    "        val_file_paths, val_labels = make_dataset(IMAGE_DIR_PATH, original_labels, USE_VAL_AUG, [1-VAL_DATA_PROPORTION, 1])\n",
    "    else :\n",
    "        train_file_paths, train_labels = make_dataset(TRAIN_DIR_PATH, original_labels, USE_TRAIN_AUG)\n",
    "        val_file_paths, val_labels = make_dataset(VAL_DIR_PATH, original_labels, USE_VAL_AUG)\n",
    "    \n",
    "    make_tfrecords_by_thread(train_file_paths, train_labels, TARGET_TRAIN)\n",
    "    make_tfrecords_by_thread(val_file_paths, val_labels, TARGET_VAL)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "\n",
    "def parse(data):\n",
    "    features = {\"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "                \"image/filename\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "                \"image/class/label\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/height\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/width\": tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "                \"image/channels\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "    parsed_features = tf.parse_single_example(data, features)\n",
    "    return parsed_features[\"image/filename\"], parsed_features[\"image/class/label\"],\\\n",
    "            parsed_features[\"image/encoded\"], parsed_features[\"image/width\"], parsed_features[\"image/height\"],\\\n",
    "            parsed_features[\"image/channels\"]\n",
    "\n",
    "def read_tfrecord(data_dir_path) :\n",
    "    label_names = load_labels(LABEL_PATH, USE_LABEL_FILE)\n",
    "    \n",
    "    tfrecord_paths = os.listdir(data_dir_path)\n",
    "    tfrecord_paths.sort()\n",
    "    \n",
    "    for tfrecord_file in tfrecord_paths :\n",
    "        tfrecord_path = os.path.join(data_dir_path, tfrecord_file)\n",
    "        print(\"tfrecord_path : {}\".format(tfrecord_path))\n",
    "        if not os.path.isfile(tfrecord_path):\n",
    "            continue\n",
    "        tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "        tfrecord_dataset = tfrecord_dataset.map(parse)\n",
    "        tfrecord_dataset = tfrecord_dataset.repeat()\n",
    "        tfrecord_dataset = tfrecord_dataset.batch(5)\n",
    "        iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "        for _ in range(2):\n",
    "            try :\n",
    "                file_name, label, image_buffer, width, height, channels = iterator.get_next()\n",
    "            except :\n",
    "                print(\"error\")\n",
    "\n",
    "            fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "            for idx in range(5) :\n",
    "                print(\"file_name : {}, label : {}\".format(file_name[idx], label[idx]))\n",
    "                image_data = tf.image.decode_jpeg(image_buffer[idx], channels=channels[idx])\n",
    "                image = tf.reshape(image_data, tf.stack([width[idx], height[idx], channels[idx]]))\n",
    "                \n",
    "                axes[idx].imshow(image)\n",
    "                axes[idx].set_title(label_names[label[idx]])\n",
    "#                 axes[idx].set_title(label[idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read_tfrecord(\"/work/nas/tfrecords/smile_final/train\")\n",
    "read_tfrecord(TRAIN_OUTPUT_DIR_PATH)\n",
    "# read_tfrecord(VAL_OUTPUT_DIR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
